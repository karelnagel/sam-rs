{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ad3bf14",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "04ec4816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from helpers import Item, input_to_file,output_to_file,random_ndarray,random_tensor,build_sam_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2de90cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import os \n",
    "import json\n",
    "from functools import reduce\n",
    "\n",
    "def set_nested_key(dct, keys, value):\n",
    "    reduce(lambda d, k: d.setdefault(k, {}), keys[:-1], dct)[keys[-1]] = value\n",
    "\n",
    "ignored_items =[\"act\",\"num_heads\",\"scale\",\"use_rel_pos\"]\n",
    "linear_names = [\"lin1\", \"lin2\",\"qkv\",\"proj\",\"q_proj\",\"k_proj\",\"v_proj\",\"out_proj\"]\n",
    "def input_to_file(file_name: str, model: nn.Module):\n",
    "    json_data = {\n",
    "        \"metadata\": {\n",
    "            \"float\": \"f32\",\n",
    "            \"int\": \"i32\",\n",
    "            \"format\": \"burn_core::record::file::FilePrettyJsonRecorder\",\n",
    "            \"version\": \"0.6.0\",\n",
    "            \"settings\": \"DebugRecordSettings\"\n",
    "        },\n",
    "        \"item\": {\n",
    "            key: None for key in ignored_items\n",
    "        }\n",
    "    }\n",
    "    for name, param in model.named_parameters():\n",
    "        keys = name.split('.')\n",
    "        param_id = str(uuid.uuid4())\n",
    "        param_shape = list(param.size())\n",
    "        print(name)\n",
    "        if name.replace(\".weight\",\"\") in linear_names:\n",
    "            print(\"transposing\"+name)\n",
    "            param = param.transpose(0,1)\n",
    "        param_value = param.flatten().detach().cpu().numpy().tolist()\n",
    "        param_data = {\n",
    "            \"id\": param_id,\n",
    "            \"param\": {\n",
    "                \"value\": param_value,\n",
    "                \"shape\": param_shape\n",
    "            }\n",
    "            \n",
    "        }\n",
    "        set_nested_key(json_data[\"item\"], keys, param_data)\n",
    "    \n",
    "    path = \"~/Documents/test-inputs/\" + file_name + '.json'\n",
    "    path = os.path.expanduser(path)\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, 'w') as json_file:\n",
    "        json.dump(json_data, json_file, indent=2)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0efaef2",
   "metadata": {},
   "source": [
    "## Common\n",
    "#### LayerNorm2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5f813cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.modeling.common import LayerNorm2d\n",
    "\n",
    "layer_norm = LayerNorm2d(256,0.1)\n",
    "\n",
    "\n",
    "# Forward\n",
    "input = random_tensor([2,256,16,16],1)\n",
    "output = layer_norm(input)\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"layer_norm_2d\",items)\n",
    "del layer_norm, input, output,items"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6a99864",
   "metadata": {},
   "source": [
    "#### MLPBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c6867373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin1.weight\n",
      "transposinglin1.weight\n",
      "lin1.bias\n",
      "lin2.weight\n",
      "transposinglin2.weight\n",
      "lin2.bias\n",
      "Linear forward torch.Size([256, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([256, 256]) torch.Size([256, 256]) torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "from segment_anything.modeling.common import MLPBlock\n",
    "mlp_block = MLPBlock(256,256,nn.GELU)\n",
    "input_to_file(\"mlp_block\",mlp_block)\n",
    "\n",
    "# Forward\n",
    "input = random_tensor([256,256],5)\n",
    "output = mlp_block(input)\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"mlp_block\",items)\n",
    "del mlp_block, input, output,items"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74fade84",
   "metadata": {},
   "source": [
    "# Image encoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56f80aac",
   "metadata": {},
   "source": [
    "#### PatchEmbeded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "08dd2d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proj.weight\n",
      "transposingproj.weight\n",
      "proj.bias\n"
     ]
    }
   ],
   "source": [
    "from segment_anything.modeling.image_encoder import PatchEmbed\n",
    "\n",
    "patch_embed = PatchEmbed((16,16),(16,16),(0,0),3,320)\n",
    "input_to_file(\"patch_embed\",patch_embed)\n",
    "\n",
    "# Forward\n",
    "input = random_tensor([1,3,512,512],3)\n",
    "output = patch_embed(input)\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"patch_embed\",items)\n",
    "del patch_embed, input, output,items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0abc93",
   "metadata": {},
   "source": [
    "#### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8241be48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.modeling.image_encoder import get_rel_pos,add_decomposed_rel_pos\n",
    "\n",
    "# Get rel pos\n",
    "q_size = 32\n",
    "k_size = 32\n",
    "input = random_tensor([127,40],1)\n",
    "output = get_rel_pos( q_size, k_size, input)\n",
    "items = [Item(\"input\",input,\"TensorFloat\"),Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"get_rel_pos\",items)\n",
    "del input, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d6dcad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add decomposed rel pos\n",
    "attn = random_tensor([200,49,49],2)\n",
    "q = random_tensor([200,49,20],3)\n",
    "relo_pos_h = random_tensor([20,20],4)\n",
    "relo_pos_w = random_tensor([20,20],5)\n",
    "q_size = (7,7)\n",
    "k_size = (7,7)\n",
    "output = add_decomposed_rel_pos(attn,q,relo_pos_h,relo_pos_w,q_size,k_size)\n",
    "items = [Item(\"attn\", attn, \"TensorFloat\"), Item(\"q\", q, \"TensorFloat\"), Item(\"q_size\", q_size, \"Size\"), Item(\"k_size\", k_size, \"Size\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"add_decomposed_rel_pos\",items)\n",
    "del attn,q,relo_pos_h,relo_pos_w,q_size,k_size,output,items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "825bf833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rel_pos_h\n",
      "rel_pos_w\n",
      "qkv.weight\n",
      "transposingqkv.weight\n",
      "qkv.bias\n",
      "proj.weight\n",
      "transposingproj.weight\n",
      "proj.bias\n",
      "Linear forward torch.Size([25, 14, 14, 320]) torch.Size([960, 320]) torch.Size([960])\n",
      "Linear forward torch.Size([25, 14, 14, 320]) torch.Size([320, 320]) torch.Size([320])\n"
     ]
    }
   ],
   "source": [
    "from segment_anything.modeling.image_encoder import Attention\n",
    "\n",
    "# Attention\n",
    "attention = Attention(320, 16 ,True ,True ,True, (14, 14))\n",
    "input_to_file(\"attention\",attention)\n",
    "\n",
    "# Forward\n",
    "input = random_tensor([25,14,14,320],1)\n",
    "output = attention(input)\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"attention\",items)\n",
    "del input\n",
    "del output\n",
    "del attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7d09b671",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.modeling.image_encoder import  window_partition,window_unpartition\n",
    "\n",
    "# Window partition\n",
    "input = random_tensor([2,256,16,16],1)\n",
    "output,size = window_partition(input,16)\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\"), Item(\"size\", size, \"Size\")]\n",
    "output_to_file(\"window_partition\",items)\n",
    "\n",
    "# Window unpartition\n",
    "input = random_tensor([2,256,16,16],2)\n",
    "output = window_unpartition(input,16,(16,16),(14,14))\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"window_unpartition\",items)\n",
    "del input, output, items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38040f69",
   "metadata": {},
   "source": [
    "#### Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5ba0e9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm1.weight\n",
      "norm1.bias\n",
      "attn.rel_pos_h\n",
      "attn.rel_pos_w\n",
      "attn.qkv.weight\n",
      "attn.qkv.bias\n",
      "attn.proj.weight\n",
      "attn.proj.bias\n",
      "norm2.weight\n",
      "norm2.bias\n",
      "mlp.lin1.weight\n",
      "mlp.lin1.bias\n",
      "mlp.lin2.weight\n",
      "mlp.lin2.bias\n",
      "Linear forward torch.Size([25, 14, 14, 320]) torch.Size([960, 320]) torch.Size([960])\n",
      "Linear forward torch.Size([25, 14, 14, 320]) torch.Size([320, 320]) torch.Size([320])\n",
      "Linear forward torch.Size([1, 64, 64, 320]) torch.Size([1280, 320]) torch.Size([1280])\n",
      "Linear forward torch.Size([1, 64, 64, 1280]) torch.Size([320, 1280]) torch.Size([320])\n"
     ]
    }
   ],
   "source": [
    "from segment_anything.modeling.image_encoder import Block\n",
    "\n",
    "#Block\n",
    "block = Block(320,16,4.0,True,nn.LayerNorm,nn.GELU,True,True,14,(64,64))\n",
    "input_to_file(\"block\",block)\n",
    "#Forward\n",
    "input = random_tensor([1,64,64,320],1)\n",
    "output = block(input)\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"block\",items)\n",
    "del block, input, output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4e1c390",
   "metadata": {},
   "source": [
    "#### Image encoderViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "83369d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_embed\n",
      "patch_embed.proj.weight\n",
      "patch_embed.proj.bias\n",
      "blocks.0.norm1.weight\n",
      "blocks.0.norm1.bias\n",
      "blocks.0.attn.rel_pos_h\n",
      "blocks.0.attn.rel_pos_w\n",
      "blocks.0.attn.qkv.weight\n",
      "blocks.0.attn.qkv.bias\n",
      "blocks.0.attn.proj.weight\n",
      "blocks.0.attn.proj.bias\n",
      "blocks.0.norm2.weight\n",
      "blocks.0.norm2.bias\n",
      "blocks.0.mlp.lin1.weight\n",
      "blocks.0.mlp.lin1.bias\n",
      "blocks.0.mlp.lin2.weight\n",
      "blocks.0.mlp.lin2.bias\n",
      "blocks.1.norm1.weight\n",
      "blocks.1.norm1.bias\n",
      "blocks.1.attn.rel_pos_h\n",
      "blocks.1.attn.rel_pos_w\n",
      "blocks.1.attn.qkv.weight\n",
      "blocks.1.attn.qkv.bias\n",
      "blocks.1.attn.proj.weight\n",
      "blocks.1.attn.proj.bias\n",
      "blocks.1.norm2.weight\n",
      "blocks.1.norm2.bias\n",
      "blocks.1.mlp.lin1.weight\n",
      "blocks.1.mlp.lin1.bias\n",
      "blocks.1.mlp.lin2.weight\n",
      "blocks.1.mlp.lin2.bias\n",
      "blocks.2.norm1.weight\n",
      "blocks.2.norm1.bias\n",
      "blocks.2.attn.rel_pos_h\n",
      "blocks.2.attn.rel_pos_w\n",
      "blocks.2.attn.qkv.weight\n",
      "blocks.2.attn.qkv.bias\n",
      "blocks.2.attn.proj.weight\n",
      "blocks.2.attn.proj.bias\n",
      "blocks.2.norm2.weight\n",
      "blocks.2.norm2.bias\n",
      "blocks.2.mlp.lin1.weight\n",
      "blocks.2.mlp.lin1.bias\n",
      "blocks.2.mlp.lin2.weight\n",
      "blocks.2.mlp.lin2.bias\n",
      "blocks.3.norm1.weight\n",
      "blocks.3.norm1.bias\n",
      "blocks.3.attn.rel_pos_h\n",
      "blocks.3.attn.rel_pos_w\n",
      "blocks.3.attn.qkv.weight\n",
      "blocks.3.attn.qkv.bias\n",
      "blocks.3.attn.proj.weight\n",
      "blocks.3.attn.proj.bias\n",
      "blocks.3.norm2.weight\n",
      "blocks.3.norm2.bias\n",
      "blocks.3.mlp.lin1.weight\n",
      "blocks.3.mlp.lin1.bias\n",
      "blocks.3.mlp.lin2.weight\n",
      "blocks.3.mlp.lin2.bias\n",
      "blocks.4.norm1.weight\n",
      "blocks.4.norm1.bias\n",
      "blocks.4.attn.rel_pos_h\n",
      "blocks.4.attn.rel_pos_w\n",
      "blocks.4.attn.qkv.weight\n",
      "blocks.4.attn.qkv.bias\n",
      "blocks.4.attn.proj.weight\n",
      "blocks.4.attn.proj.bias\n",
      "blocks.4.norm2.weight\n",
      "blocks.4.norm2.bias\n",
      "blocks.4.mlp.lin1.weight\n",
      "blocks.4.mlp.lin1.bias\n",
      "blocks.4.mlp.lin2.weight\n",
      "blocks.4.mlp.lin2.bias\n",
      "blocks.5.norm1.weight\n",
      "blocks.5.norm1.bias\n",
      "blocks.5.attn.rel_pos_h\n",
      "blocks.5.attn.rel_pos_w\n",
      "blocks.5.attn.qkv.weight\n",
      "blocks.5.attn.qkv.bias\n",
      "blocks.5.attn.proj.weight\n",
      "blocks.5.attn.proj.bias\n",
      "blocks.5.norm2.weight\n",
      "blocks.5.norm2.bias\n",
      "blocks.5.mlp.lin1.weight\n",
      "blocks.5.mlp.lin1.bias\n",
      "blocks.5.mlp.lin2.weight\n",
      "blocks.5.mlp.lin2.bias\n",
      "blocks.6.norm1.weight\n",
      "blocks.6.norm1.bias\n",
      "blocks.6.attn.rel_pos_h\n",
      "blocks.6.attn.rel_pos_w\n",
      "blocks.6.attn.qkv.weight\n",
      "blocks.6.attn.qkv.bias\n",
      "blocks.6.attn.proj.weight\n",
      "blocks.6.attn.proj.bias\n",
      "blocks.6.norm2.weight\n",
      "blocks.6.norm2.bias\n",
      "blocks.6.mlp.lin1.weight\n",
      "blocks.6.mlp.lin1.bias\n",
      "blocks.6.mlp.lin2.weight\n",
      "blocks.6.mlp.lin2.bias\n",
      "blocks.7.norm1.weight\n",
      "blocks.7.norm1.bias\n",
      "blocks.7.attn.rel_pos_h\n",
      "blocks.7.attn.rel_pos_w\n",
      "blocks.7.attn.qkv.weight\n",
      "blocks.7.attn.qkv.bias\n",
      "blocks.7.attn.proj.weight\n",
      "blocks.7.attn.proj.bias\n",
      "blocks.7.norm2.weight\n",
      "blocks.7.norm2.bias\n",
      "blocks.7.mlp.lin1.weight\n",
      "blocks.7.mlp.lin1.bias\n",
      "blocks.7.mlp.lin2.weight\n",
      "blocks.7.mlp.lin2.bias\n",
      "blocks.8.norm1.weight\n",
      "blocks.8.norm1.bias\n",
      "blocks.8.attn.rel_pos_h\n",
      "blocks.8.attn.rel_pos_w\n",
      "blocks.8.attn.qkv.weight\n",
      "blocks.8.attn.qkv.bias\n",
      "blocks.8.attn.proj.weight\n",
      "blocks.8.attn.proj.bias\n",
      "blocks.8.norm2.weight\n",
      "blocks.8.norm2.bias\n",
      "blocks.8.mlp.lin1.weight\n",
      "blocks.8.mlp.lin1.bias\n",
      "blocks.8.mlp.lin2.weight\n",
      "blocks.8.mlp.lin2.bias\n",
      "blocks.9.norm1.weight\n",
      "blocks.9.norm1.bias\n",
      "blocks.9.attn.rel_pos_h\n",
      "blocks.9.attn.rel_pos_w\n",
      "blocks.9.attn.qkv.weight\n",
      "blocks.9.attn.qkv.bias\n",
      "blocks.9.attn.proj.weight\n",
      "blocks.9.attn.proj.bias\n",
      "blocks.9.norm2.weight\n",
      "blocks.9.norm2.bias\n",
      "blocks.9.mlp.lin1.weight\n",
      "blocks.9.mlp.lin1.bias\n",
      "blocks.9.mlp.lin2.weight\n",
      "blocks.9.mlp.lin2.bias\n",
      "blocks.10.norm1.weight\n",
      "blocks.10.norm1.bias\n",
      "blocks.10.attn.rel_pos_h\n",
      "blocks.10.attn.rel_pos_w\n",
      "blocks.10.attn.qkv.weight\n",
      "blocks.10.attn.qkv.bias\n",
      "blocks.10.attn.proj.weight\n",
      "blocks.10.attn.proj.bias\n",
      "blocks.10.norm2.weight\n",
      "blocks.10.norm2.bias\n",
      "blocks.10.mlp.lin1.weight\n",
      "blocks.10.mlp.lin1.bias\n",
      "blocks.10.mlp.lin2.weight\n",
      "blocks.10.mlp.lin2.bias\n",
      "blocks.11.norm1.weight\n",
      "blocks.11.norm1.bias\n",
      "blocks.11.attn.rel_pos_h\n",
      "blocks.11.attn.rel_pos_w\n",
      "blocks.11.attn.qkv.weight\n",
      "blocks.11.attn.qkv.bias\n",
      "blocks.11.attn.proj.weight\n",
      "blocks.11.attn.proj.bias\n",
      "blocks.11.norm2.weight\n",
      "blocks.11.norm2.bias\n",
      "blocks.11.mlp.lin1.weight\n",
      "blocks.11.mlp.lin1.bias\n",
      "blocks.11.mlp.lin2.weight\n",
      "blocks.11.mlp.lin2.bias\n",
      "blocks.12.norm1.weight\n",
      "blocks.12.norm1.bias\n",
      "blocks.12.attn.rel_pos_h\n",
      "blocks.12.attn.rel_pos_w\n",
      "blocks.12.attn.qkv.weight\n",
      "blocks.12.attn.qkv.bias\n",
      "blocks.12.attn.proj.weight\n",
      "blocks.12.attn.proj.bias\n",
      "blocks.12.norm2.weight\n",
      "blocks.12.norm2.bias\n",
      "blocks.12.mlp.lin1.weight\n",
      "blocks.12.mlp.lin1.bias\n",
      "blocks.12.mlp.lin2.weight\n",
      "blocks.12.mlp.lin2.bias\n",
      "blocks.13.norm1.weight\n",
      "blocks.13.norm1.bias\n",
      "blocks.13.attn.rel_pos_h\n",
      "blocks.13.attn.rel_pos_w\n",
      "blocks.13.attn.qkv.weight\n",
      "blocks.13.attn.qkv.bias\n",
      "blocks.13.attn.proj.weight\n",
      "blocks.13.attn.proj.bias\n",
      "blocks.13.norm2.weight\n",
      "blocks.13.norm2.bias\n",
      "blocks.13.mlp.lin1.weight\n",
      "blocks.13.mlp.lin1.bias\n",
      "blocks.13.mlp.lin2.weight\n",
      "blocks.13.mlp.lin2.bias\n",
      "blocks.14.norm1.weight\n",
      "blocks.14.norm1.bias\n",
      "blocks.14.attn.rel_pos_h\n",
      "blocks.14.attn.rel_pos_w\n",
      "blocks.14.attn.qkv.weight\n",
      "blocks.14.attn.qkv.bias\n",
      "blocks.14.attn.proj.weight\n",
      "blocks.14.attn.proj.bias\n",
      "blocks.14.norm2.weight\n",
      "blocks.14.norm2.bias\n",
      "blocks.14.mlp.lin1.weight\n",
      "blocks.14.mlp.lin1.bias\n",
      "blocks.14.mlp.lin2.weight\n",
      "blocks.14.mlp.lin2.bias\n",
      "blocks.15.norm1.weight\n",
      "blocks.15.norm1.bias\n",
      "blocks.15.attn.rel_pos_h\n",
      "blocks.15.attn.rel_pos_w\n",
      "blocks.15.attn.qkv.weight\n",
      "blocks.15.attn.qkv.bias\n",
      "blocks.15.attn.proj.weight\n",
      "blocks.15.attn.proj.bias\n",
      "blocks.15.norm2.weight\n",
      "blocks.15.norm2.bias\n",
      "blocks.15.mlp.lin1.weight\n",
      "blocks.15.mlp.lin1.bias\n",
      "blocks.15.mlp.lin2.weight\n",
      "blocks.15.mlp.lin2.bias\n",
      "blocks.16.norm1.weight\n",
      "blocks.16.norm1.bias\n",
      "blocks.16.attn.rel_pos_h\n",
      "blocks.16.attn.rel_pos_w\n",
      "blocks.16.attn.qkv.weight\n",
      "blocks.16.attn.qkv.bias\n",
      "blocks.16.attn.proj.weight\n",
      "blocks.16.attn.proj.bias\n",
      "blocks.16.norm2.weight\n",
      "blocks.16.norm2.bias\n",
      "blocks.16.mlp.lin1.weight\n",
      "blocks.16.mlp.lin1.bias\n",
      "blocks.16.mlp.lin2.weight\n",
      "blocks.16.mlp.lin2.bias\n",
      "blocks.17.norm1.weight\n",
      "blocks.17.norm1.bias\n",
      "blocks.17.attn.rel_pos_h\n",
      "blocks.17.attn.rel_pos_w\n",
      "blocks.17.attn.qkv.weight\n",
      "blocks.17.attn.qkv.bias\n",
      "blocks.17.attn.proj.weight\n",
      "blocks.17.attn.proj.bias\n",
      "blocks.17.norm2.weight\n",
      "blocks.17.norm2.bias\n",
      "blocks.17.mlp.lin1.weight\n",
      "blocks.17.mlp.lin1.bias\n",
      "blocks.17.mlp.lin2.weight\n",
      "blocks.17.mlp.lin2.bias\n",
      "blocks.18.norm1.weight\n",
      "blocks.18.norm1.bias\n",
      "blocks.18.attn.rel_pos_h\n",
      "blocks.18.attn.rel_pos_w\n",
      "blocks.18.attn.qkv.weight\n",
      "blocks.18.attn.qkv.bias\n",
      "blocks.18.attn.proj.weight\n",
      "blocks.18.attn.proj.bias\n",
      "blocks.18.norm2.weight\n",
      "blocks.18.norm2.bias\n",
      "blocks.18.mlp.lin1.weight\n",
      "blocks.18.mlp.lin1.bias\n",
      "blocks.18.mlp.lin2.weight\n",
      "blocks.18.mlp.lin2.bias\n",
      "blocks.19.norm1.weight\n",
      "blocks.19.norm1.bias\n",
      "blocks.19.attn.rel_pos_h\n",
      "blocks.19.attn.rel_pos_w\n",
      "blocks.19.attn.qkv.weight\n",
      "blocks.19.attn.qkv.bias\n",
      "blocks.19.attn.proj.weight\n",
      "blocks.19.attn.proj.bias\n",
      "blocks.19.norm2.weight\n",
      "blocks.19.norm2.bias\n",
      "blocks.19.mlp.lin1.weight\n",
      "blocks.19.mlp.lin1.bias\n",
      "blocks.19.mlp.lin2.weight\n",
      "blocks.19.mlp.lin2.bias\n",
      "blocks.20.norm1.weight\n",
      "blocks.20.norm1.bias\n",
      "blocks.20.attn.rel_pos_h\n",
      "blocks.20.attn.rel_pos_w\n",
      "blocks.20.attn.qkv.weight\n",
      "blocks.20.attn.qkv.bias\n",
      "blocks.20.attn.proj.weight\n",
      "blocks.20.attn.proj.bias\n",
      "blocks.20.norm2.weight\n",
      "blocks.20.norm2.bias\n",
      "blocks.20.mlp.lin1.weight\n",
      "blocks.20.mlp.lin1.bias\n",
      "blocks.20.mlp.lin2.weight\n",
      "blocks.20.mlp.lin2.bias\n",
      "blocks.21.norm1.weight\n",
      "blocks.21.norm1.bias\n",
      "blocks.21.attn.rel_pos_h\n",
      "blocks.21.attn.rel_pos_w\n",
      "blocks.21.attn.qkv.weight\n",
      "blocks.21.attn.qkv.bias\n",
      "blocks.21.attn.proj.weight\n",
      "blocks.21.attn.proj.bias\n",
      "blocks.21.norm2.weight\n",
      "blocks.21.norm2.bias\n",
      "blocks.21.mlp.lin1.weight\n",
      "blocks.21.mlp.lin1.bias\n",
      "blocks.21.mlp.lin2.weight\n",
      "blocks.21.mlp.lin2.bias\n",
      "blocks.22.norm1.weight\n",
      "blocks.22.norm1.bias\n",
      "blocks.22.attn.rel_pos_h\n",
      "blocks.22.attn.rel_pos_w\n",
      "blocks.22.attn.qkv.weight\n",
      "blocks.22.attn.qkv.bias\n",
      "blocks.22.attn.proj.weight\n",
      "blocks.22.attn.proj.bias\n",
      "blocks.22.norm2.weight\n",
      "blocks.22.norm2.bias\n",
      "blocks.22.mlp.lin1.weight\n",
      "blocks.22.mlp.lin1.bias\n",
      "blocks.22.mlp.lin2.weight\n",
      "blocks.22.mlp.lin2.bias\n",
      "blocks.23.norm1.weight\n",
      "blocks.23.norm1.bias\n",
      "blocks.23.attn.rel_pos_h\n",
      "blocks.23.attn.rel_pos_w\n",
      "blocks.23.attn.qkv.weight\n",
      "blocks.23.attn.qkv.bias\n",
      "blocks.23.attn.proj.weight\n",
      "blocks.23.attn.proj.bias\n",
      "blocks.23.norm2.weight\n",
      "blocks.23.norm2.bias\n",
      "blocks.23.mlp.lin1.weight\n",
      "blocks.23.mlp.lin1.bias\n",
      "blocks.23.mlp.lin2.weight\n",
      "blocks.23.mlp.lin2.bias\n",
      "blocks.24.norm1.weight\n",
      "blocks.24.norm1.bias\n",
      "blocks.24.attn.rel_pos_h\n",
      "blocks.24.attn.rel_pos_w\n",
      "blocks.24.attn.qkv.weight\n",
      "blocks.24.attn.qkv.bias\n",
      "blocks.24.attn.proj.weight\n",
      "blocks.24.attn.proj.bias\n",
      "blocks.24.norm2.weight\n",
      "blocks.24.norm2.bias\n",
      "blocks.24.mlp.lin1.weight\n",
      "blocks.24.mlp.lin1.bias\n",
      "blocks.24.mlp.lin2.weight\n",
      "blocks.24.mlp.lin2.bias\n",
      "blocks.25.norm1.weight\n",
      "blocks.25.norm1.bias\n",
      "blocks.25.attn.rel_pos_h\n",
      "blocks.25.attn.rel_pos_w\n",
      "blocks.25.attn.qkv.weight\n",
      "blocks.25.attn.qkv.bias\n",
      "blocks.25.attn.proj.weight\n",
      "blocks.25.attn.proj.bias\n",
      "blocks.25.norm2.weight\n",
      "blocks.25.norm2.bias\n",
      "blocks.25.mlp.lin1.weight\n",
      "blocks.25.mlp.lin1.bias\n",
      "blocks.25.mlp.lin2.weight\n",
      "blocks.25.mlp.lin2.bias\n",
      "blocks.26.norm1.weight\n",
      "blocks.26.norm1.bias\n",
      "blocks.26.attn.rel_pos_h\n",
      "blocks.26.attn.rel_pos_w\n",
      "blocks.26.attn.qkv.weight\n",
      "blocks.26.attn.qkv.bias\n",
      "blocks.26.attn.proj.weight\n",
      "blocks.26.attn.proj.bias\n",
      "blocks.26.norm2.weight\n",
      "blocks.26.norm2.bias\n",
      "blocks.26.mlp.lin1.weight\n",
      "blocks.26.mlp.lin1.bias\n",
      "blocks.26.mlp.lin2.weight\n",
      "blocks.26.mlp.lin2.bias\n",
      "blocks.27.norm1.weight\n",
      "blocks.27.norm1.bias\n",
      "blocks.27.attn.rel_pos_h\n",
      "blocks.27.attn.rel_pos_w\n",
      "blocks.27.attn.qkv.weight\n",
      "blocks.27.attn.qkv.bias\n",
      "blocks.27.attn.proj.weight\n",
      "blocks.27.attn.proj.bias\n",
      "blocks.27.norm2.weight\n",
      "blocks.27.norm2.bias\n",
      "blocks.27.mlp.lin1.weight\n",
      "blocks.27.mlp.lin1.bias\n",
      "blocks.27.mlp.lin2.weight\n",
      "blocks.27.mlp.lin2.bias\n",
      "blocks.28.norm1.weight\n",
      "blocks.28.norm1.bias\n",
      "blocks.28.attn.rel_pos_h\n",
      "blocks.28.attn.rel_pos_w\n",
      "blocks.28.attn.qkv.weight\n",
      "blocks.28.attn.qkv.bias\n",
      "blocks.28.attn.proj.weight\n",
      "blocks.28.attn.proj.bias\n",
      "blocks.28.norm2.weight\n",
      "blocks.28.norm2.bias\n",
      "blocks.28.mlp.lin1.weight\n",
      "blocks.28.mlp.lin1.bias\n",
      "blocks.28.mlp.lin2.weight\n",
      "blocks.28.mlp.lin2.bias\n",
      "blocks.29.norm1.weight\n",
      "blocks.29.norm1.bias\n",
      "blocks.29.attn.rel_pos_h\n",
      "blocks.29.attn.rel_pos_w\n",
      "blocks.29.attn.qkv.weight\n",
      "blocks.29.attn.qkv.bias\n",
      "blocks.29.attn.proj.weight\n",
      "blocks.29.attn.proj.bias\n",
      "blocks.29.norm2.weight\n",
      "blocks.29.norm2.bias\n",
      "blocks.29.mlp.lin1.weight\n",
      "blocks.29.mlp.lin1.bias\n",
      "blocks.29.mlp.lin2.weight\n",
      "blocks.29.mlp.lin2.bias\n",
      "blocks.30.norm1.weight\n",
      "blocks.30.norm1.bias\n",
      "blocks.30.attn.rel_pos_h\n",
      "blocks.30.attn.rel_pos_w\n",
      "blocks.30.attn.qkv.weight\n",
      "blocks.30.attn.qkv.bias\n",
      "blocks.30.attn.proj.weight\n",
      "blocks.30.attn.proj.bias\n",
      "blocks.30.norm2.weight\n",
      "blocks.30.norm2.bias\n",
      "blocks.30.mlp.lin1.weight\n",
      "blocks.30.mlp.lin1.bias\n",
      "blocks.30.mlp.lin2.weight\n",
      "blocks.30.mlp.lin2.bias\n",
      "blocks.31.norm1.weight\n",
      "blocks.31.norm1.bias\n",
      "blocks.31.attn.rel_pos_h\n",
      "blocks.31.attn.rel_pos_w\n",
      "blocks.31.attn.qkv.weight\n",
      "blocks.31.attn.qkv.bias\n",
      "blocks.31.attn.proj.weight\n",
      "blocks.31.attn.proj.bias\n",
      "blocks.31.norm2.weight\n",
      "blocks.31.norm2.bias\n",
      "blocks.31.mlp.lin1.weight\n",
      "blocks.31.mlp.lin1.bias\n",
      "blocks.31.mlp.lin2.weight\n",
      "blocks.31.mlp.lin2.bias\n",
      "neck.0.weight\n",
      "neck.1.weight\n",
      "neck.1.bias\n",
      "neck.2.weight\n",
      "neck.3.weight\n",
      "neck.3.bias\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([240, 80]) torch.Size([240])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([80, 80]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([320, 80]) torch.Size([320])\n",
      "Linear forward torch.Size([1, 8, 8, 320]) torch.Size([80, 320]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([240, 80]) torch.Size([240])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([80, 80]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([320, 80]) torch.Size([320])\n",
      "Linear forward torch.Size([1, 8, 8, 320]) torch.Size([80, 320]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([240, 80]) torch.Size([240])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([80, 80]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([320, 80]) torch.Size([320])\n",
      "Linear forward torch.Size([1, 8, 8, 320]) torch.Size([80, 320]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([240, 80]) torch.Size([240])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([80, 80]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([320, 80]) torch.Size([320])\n",
      "Linear forward torch.Size([1, 8, 8, 320]) torch.Size([80, 320]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([240, 80]) torch.Size([240])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([80, 80]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([320, 80]) torch.Size([320])\n",
      "Linear forward torch.Size([1, 8, 8, 320]) torch.Size([80, 320]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([240, 80]) torch.Size([240])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([80, 80]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([320, 80]) torch.Size([320])\n",
      "Linear forward torch.Size([1, 8, 8, 320]) torch.Size([80, 320]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([240, 80]) torch.Size([240])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([80, 80]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([320, 80]) torch.Size([320])\n",
      "Linear forward torch.Size([1, 8, 8, 320]) torch.Size([80, 320]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([240, 80]) torch.Size([240])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([80, 80]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([320, 80]) torch.Size([320])\n",
      "Linear forward torch.Size([1, 8, 8, 320]) torch.Size([80, 320]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([240, 80]) torch.Size([240])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([80, 80]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([320, 80]) torch.Size([320])\n",
      "Linear forward torch.Size([1, 8, 8, 320]) torch.Size([80, 320]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([240, 80]) torch.Size([240])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([80, 80]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([320, 80]) torch.Size([320])\n",
      "Linear forward torch.Size([1, 8, 8, 320]) torch.Size([80, 320]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([240, 80]) torch.Size([240])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([80, 80]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([320, 80]) torch.Size([320])\n",
      "Linear forward torch.Size([1, 8, 8, 320]) torch.Size([80, 320]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([240, 80]) torch.Size([240])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([80, 80]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([320, 80]) torch.Size([320])\n",
      "Linear forward torch.Size([1, 8, 8, 320]) torch.Size([80, 320]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([240, 80]) torch.Size([240])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([80, 80]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([320, 80]) torch.Size([320])\n",
      "Linear forward torch.Size([1, 8, 8, 320]) torch.Size([80, 320]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([240, 80]) torch.Size([240])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([80, 80]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([320, 80]) torch.Size([320])\n",
      "Linear forward torch.Size([1, 8, 8, 320]) torch.Size([80, 320]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([240, 80]) torch.Size([240])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([80, 80]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([320, 80]) torch.Size([320])\n",
      "Linear forward torch.Size([1, 8, 8, 320]) torch.Size([80, 320]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([240, 80]) torch.Size([240])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([80, 80]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([320, 80]) torch.Size([320])\n",
      "Linear forward torch.Size([1, 8, 8, 320]) torch.Size([80, 320]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([240, 80]) torch.Size([240])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([80, 80]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([320, 80]) torch.Size([320])\n",
      "Linear forward torch.Size([1, 8, 8, 320]) torch.Size([80, 320]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([240, 80]) torch.Size([240])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([80, 80]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([320, 80]) torch.Size([320])\n",
      "Linear forward torch.Size([1, 8, 8, 320]) torch.Size([80, 320]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([240, 80]) torch.Size([240])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([80, 80]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([320, 80]) torch.Size([320])\n",
      "Linear forward torch.Size([1, 8, 8, 320]) torch.Size([80, 320]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([240, 80]) torch.Size([240])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([80, 80]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([320, 80]) torch.Size([320])\n",
      "Linear forward torch.Size([1, 8, 8, 320]) torch.Size([80, 320]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([240, 80]) torch.Size([240])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([80, 80]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([320, 80]) torch.Size([320])\n",
      "Linear forward torch.Size([1, 8, 8, 320]) torch.Size([80, 320]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([240, 80]) torch.Size([240])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([80, 80]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([320, 80]) torch.Size([320])\n",
      "Linear forward torch.Size([1, 8, 8, 320]) torch.Size([80, 320]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([240, 80]) torch.Size([240])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([80, 80]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([320, 80]) torch.Size([320])\n",
      "Linear forward torch.Size([1, 8, 8, 320]) torch.Size([80, 320]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([240, 80]) torch.Size([240])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([80, 80]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([320, 80]) torch.Size([320])\n",
      "Linear forward torch.Size([1, 8, 8, 320]) torch.Size([80, 320]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([240, 80]) torch.Size([240])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([80, 80]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([320, 80]) torch.Size([320])\n",
      "Linear forward torch.Size([1, 8, 8, 320]) torch.Size([80, 320]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([240, 80]) torch.Size([240])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([80, 80]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([320, 80]) torch.Size([320])\n",
      "Linear forward torch.Size([1, 8, 8, 320]) torch.Size([80, 320]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([240, 80]) torch.Size([240])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([80, 80]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([320, 80]) torch.Size([320])\n",
      "Linear forward torch.Size([1, 8, 8, 320]) torch.Size([80, 320]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([240, 80]) torch.Size([240])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([80, 80]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([320, 80]) torch.Size([320])\n",
      "Linear forward torch.Size([1, 8, 8, 320]) torch.Size([80, 320]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([240, 80]) torch.Size([240])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([80, 80]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([320, 80]) torch.Size([320])\n",
      "Linear forward torch.Size([1, 8, 8, 320]) torch.Size([80, 320]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([240, 80]) torch.Size([240])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([80, 80]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([320, 80]) torch.Size([320])\n",
      "Linear forward torch.Size([1, 8, 8, 320]) torch.Size([80, 320]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([240, 80]) torch.Size([240])\n",
      "Linear forward torch.Size([1, 14, 14, 80]) torch.Size([80, 80]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([320, 80]) torch.Size([320])\n",
      "Linear forward torch.Size([1, 8, 8, 320]) torch.Size([80, 320]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([240, 80]) torch.Size([240])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([80, 80]) torch.Size([80])\n",
      "Linear forward torch.Size([1, 8, 8, 80]) torch.Size([320, 80]) torch.Size([320])\n",
      "Linear forward torch.Size([1, 8, 8, 320]) torch.Size([80, 320]) torch.Size([80])\n"
     ]
    }
   ],
   "source": [
    "from segment_anything.modeling.image_encoder import ImageEncoderViT\n",
    "\n",
    "image_encoder = ImageEncoderViT(32,4,3,80,32,16,4.0,256,True,nn.LayerNorm,nn.GELU,True,True,True,14,[7,15,23,31])\n",
    "input_to_file(\"image_encoder\",image_encoder)\n",
    "\n",
    "input = random_tensor([1,3,32,32],1)\n",
    "output = image_encoder(input)\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"image_encoder\",items)\n",
    "\n",
    "del image_encoder\n",
    "del input\n",
    "del output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66c6f570",
   "metadata": {},
   "source": [
    "## Transformer\n",
    "#### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ee398610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q_proj.weight\n",
      "transposingq_proj.weight\n",
      "q_proj.bias\n",
      "k_proj.weight\n",
      "transposingk_proj.weight\n",
      "k_proj.bias\n",
      "v_proj.weight\n",
      "transposingv_proj.weight\n",
      "v_proj.bias\n",
      "out_proj.weight\n",
      "transposingout_proj.weight\n",
      "out_proj.bias\n",
      "Linear forward torch.Size([1, 32, 32]) torch.Size([32, 32]) torch.Size([32])\n",
      "Linear forward torch.Size([1, 32, 32]) torch.Size([32, 32]) torch.Size([32])\n",
      "Linear forward torch.Size([1, 32, 32]) torch.Size([32, 32]) torch.Size([32])\n",
      "Linear forward torch.Size([1, 32, 32]) torch.Size([32, 32]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "from segment_anything.modeling.transformer import Attention\n",
    "\n",
    "attention = Attention(32,8,1)\n",
    "input_to_file(\"transformer_attention\",attention)\n",
    "\n",
    "#Forward\n",
    "q = random_tensor([1,32,32],1)\n",
    "k = random_tensor([1,32,32],2)\n",
    "v = random_tensor([1,32,32],3)\n",
    "output = attention.forward(q,k,v)\n",
    "items = [Item(\"q\", q, \"TensorFloat\"), Item(\"k\", k, \"TensorFloat\"), Item(\"v\", v, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"transformer_attention\",items)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c1c5c01",
   "metadata": {},
   "source": [
    "#### TwoWayAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "48ea625b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self_attn.q_proj.weight\n",
      "self_attn.q_proj.bias\n",
      "self_attn.k_proj.weight\n",
      "self_attn.k_proj.bias\n",
      "self_attn.v_proj.weight\n",
      "self_attn.v_proj.bias\n",
      "self_attn.out_proj.weight\n",
      "self_attn.out_proj.bias\n",
      "norm1.weight\n",
      "norm1.bias\n",
      "cross_attn_token_to_image.q_proj.weight\n",
      "cross_attn_token_to_image.q_proj.bias\n",
      "cross_attn_token_to_image.k_proj.weight\n",
      "cross_attn_token_to_image.k_proj.bias\n",
      "cross_attn_token_to_image.v_proj.weight\n",
      "cross_attn_token_to_image.v_proj.bias\n",
      "cross_attn_token_to_image.out_proj.weight\n",
      "cross_attn_token_to_image.out_proj.bias\n",
      "norm2.weight\n",
      "norm2.bias\n",
      "mlp.lin1.weight\n",
      "mlp.lin1.bias\n",
      "mlp.lin2.weight\n",
      "mlp.lin2.bias\n",
      "norm3.weight\n",
      "norm3.bias\n",
      "norm4.weight\n",
      "norm4.bias\n",
      "cross_attn_image_to_token.q_proj.weight\n",
      "cross_attn_image_to_token.q_proj.bias\n",
      "cross_attn_image_to_token.k_proj.weight\n",
      "cross_attn_image_to_token.k_proj.bias\n",
      "cross_attn_image_to_token.v_proj.weight\n",
      "cross_attn_image_to_token.v_proj.bias\n",
      "cross_attn_image_to_token.out_proj.weight\n",
      "cross_attn_image_to_token.out_proj.bias\n"
     ]
    }
   ],
   "source": [
    "from segment_anything.modeling.transformer import TwoWayAttentionBlock\n",
    "\n",
    "block = TwoWayAttentionBlock(256,8,2048,nn.ReLU,2,False)\n",
    "input_to_file(\"transformer_two_way_attention_block\",block)\n",
    "\n",
    "#Forward\n",
    "queries = random_tensor([1,256,256],1)\n",
    "keys = random_tensor([1,256,256],2)\n",
    "query_pe = random_tensor([1,256,256],3)\n",
    "key_pe = random_tensor([1,256,256],4)\n",
    "out_queries,out_keys = block(queries,keys,query_pe,key_pe)\n",
    "items = [Item(\"queries\", queries, \"TensorFloat\"), Item(\"keys\", keys, \"TensorFloat\"), Item(\"query_pe\", query_pe, \"TensorFloat\"), Item(\"key_pe\", key_pe, \"TensorFloat\"), Item(\"out_queries\", out_queries, \"TensorFloat\"), Item(\"out_keys\", out_keys, \"TensorFloat\")]\n",
    "output_to_file(\"transformer_two_way_attention_block\",items)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3168b933",
   "metadata": {},
   "source": [
    "#### TwoWayTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fa73fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear forward torch.Size([16, 256, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([1, 256, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([1, 256, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 256, 32]) torch.Size([64, 32]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([256, 64]) torch.Size([256])\n",
      "Linear forward torch.Size([16, 256, 256]) torch.Size([64, 256]) torch.Size([64])\n",
      "Linear forward torch.Size([1, 256, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 256, 32]) torch.Size([64, 32]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 256, 32]) torch.Size([64, 32]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([256, 64]) torch.Size([256])\n",
      "Linear forward torch.Size([16, 256, 256]) torch.Size([64, 256]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 256, 32]) torch.Size([64, 32]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 256, 32]) torch.Size([64, 32]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "from segment_anything.modeling.transformer import TwoWayTransformer\n",
    "\n",
    "transformer = TwoWayTransformer(2, 64, 4, 256, nn.ReLU, 2)\n",
    "input_to_file(\"transformer_two_way_transformer\",transformer)\n",
    "\n",
    "# Forward\n",
    "image_embedding = random_tensor([1,64,16,16],1)\n",
    "image_pe = random_tensor([1,64,16,16],2)\n",
    "point_embedding = random_tensor([16, 256, 64],3)\n",
    "queries,keys = transformer(image_embedding,image_pe,point_embedding)\n",
    "items = [Item(\"image_embedding\", image_embedding, \"TensorFloat\"), Item(\"image_pe\", image_pe, \"TensorFloat\"), Item(\"point_embedding\", point_embedding, \"TensorFloat\"), Item(\"queries\", queries, \"TensorFloat\"), Item(\"keys\", keys, \"TensorFloat\")]\n",
    "output_to_file(\"transformer_two_way_transformer\",items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d5a673",
   "metadata": {},
   "source": [
    "## Mask decoder\n",
    "#### MLP block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a847818d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear forward torch.Size([1, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 256]) torch.Size([256, 256]) torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "from segment_anything.modeling.mask_decoder import MLP\n",
    "\n",
    "mlp = MLP(256,256,256,4,False)\n",
    "input_to_file(\"mlp\",mlp)\n",
    "\n",
    "# Forward\n",
    "input = random_tensor([1,256],1)\n",
    "output = mlp(input)\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"mlp\",items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088e4ce7",
   "metadata": {},
   "source": [
    "#### Mask decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75fa9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear forward torch.Size([16, 7, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 7, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 7, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 7, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 7, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 7, 32]) torch.Size([64, 32]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 7, 64]) torch.Size([512, 64]) torch.Size([512])\n",
      "Linear forward torch.Size([16, 7, 512]) torch.Size([64, 512]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 7, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 7, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 256, 32]) torch.Size([64, 32]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 7, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 7, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 7, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 7, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 7, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 7, 32]) torch.Size([64, 32]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 7, 64]) torch.Size([512, 64]) torch.Size([512])\n",
      "Linear forward torch.Size([16, 7, 512]) torch.Size([64, 512]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 7, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 7, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 256, 32]) torch.Size([64, 32]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 7, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 7, 32]) torch.Size([64, 32]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 64]) torch.Size([8, 64]) torch.Size([8])\n",
      "Linear forward torch.Size([16, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 64]) torch.Size([8, 64]) torch.Size([8])\n",
      "Linear forward torch.Size([16, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 64]) torch.Size([8, 64]) torch.Size([8])\n",
      "Linear forward torch.Size([16, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 64]) torch.Size([8, 64]) torch.Size([8])\n",
      "Linear forward torch.Size([16, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 64]) torch.Size([4, 64]) torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "from segment_anything.modeling.mask_decoder import MaskDecoder\n",
    "\n",
    "transformer = TwoWayTransformer(2, 64, 2, 512, nn.ReLU, 2)\n",
    "mask_decoder = MaskDecoder(transformer_dim=64,transformer=transformer,num_multimask_outputs=3, activation=nn.GELU,iou_head_depth=3,iou_head_hidden_dim=64)\n",
    "input_to_file(\"mask_decoder\",mask_decoder)\n",
    "\n",
    "# Forward\n",
    "image_embedding = random_tensor([1,64,16,16],1)\n",
    "image_pe = random_tensor([1,64,16,16],2)\n",
    "sparse_prompt_embeddings = random_tensor([16, 2, 64],3)\n",
    "dense_prompt_embeddings = random_tensor([16, 64, 16, 16],4)\n",
    "masks, iou_pred = mask_decoder(image_embedding,image_pe,sparse_prompt_embeddings,dense_prompt_embeddings,True)\n",
    "items = [Item(\"image_embedding\", image_embedding, \"TensorFloat\"), Item(\"image_pe\", image_pe, \"TensorFloat\"), Item(\"sparse_prompt_embeddings\", sparse_prompt_embeddings, \"TensorFloat\"), Item(\"dense_prompt_embeddings\", dense_prompt_embeddings, \"TensorFloat\"), Item(\"masks\", masks, \"TensorFloat\"), Item(\"iou_pred\", iou_pred, \"TensorFloat\")]\n",
    "output_to_file(\"mask_decoder\",items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a404f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear forward torch.Size([16, 7, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 7, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 7, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 7, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 7, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 7, 32]) torch.Size([64, 32]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 7, 64]) torch.Size([512, 64]) torch.Size([512])\n",
      "Linear forward torch.Size([16, 7, 512]) torch.Size([64, 512]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 7, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 7, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 256, 32]) torch.Size([64, 32]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 7, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 7, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 7, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 7, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 7, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 7, 32]) torch.Size([64, 32]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 7, 64]) torch.Size([512, 64]) torch.Size([512])\n",
      "Linear forward torch.Size([16, 7, 512]) torch.Size([64, 512]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 7, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 7, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 256, 32]) torch.Size([64, 32]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 7, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 256, 64]) torch.Size([32, 64]) torch.Size([32])\n",
      "Linear forward torch.Size([16, 7, 32]) torch.Size([64, 32]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 64]) torch.Size([8, 64]) torch.Size([8])\n",
      "Linear forward torch.Size([16, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 64]) torch.Size([8, 64]) torch.Size([8])\n",
      "Linear forward torch.Size([16, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 64]) torch.Size([8, 64]) torch.Size([8])\n",
      "Linear forward torch.Size([16, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 64]) torch.Size([8, 64]) torch.Size([8])\n",
      "Linear forward torch.Size([16, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([16, 64]) torch.Size([4, 64]) torch.Size([4])\n",
      "asas torch.Size([16, 4, 64, 64]) torch.Size([16, 4])\n"
     ]
    }
   ],
   "source": [
    "# Predict masks\n",
    "transformer = TwoWayTransformer(2, 64, 2, 512, nn.ReLU, 2)\n",
    "mask_decoder = MaskDecoder(transformer_dim=64,transformer=transformer,num_multimask_outputs=3, activation=nn.GELU,iou_head_depth=3,iou_head_hidden_dim=64)\n",
    "input_to_file(\"mask_decoder_predict\",mask_decoder)\n",
    "\n",
    "# Predict masks\n",
    "image_embedding = random_tensor([1,64,16,16],1)\n",
    "image_pe = random_tensor([1,64,16,16],2)\n",
    "sparse_prompt_embeddings = random_tensor([16, 2, 64],3)\n",
    "dense_prompt_embeddings = random_tensor([16, 64, 16, 16],4)\n",
    "masks, iou_pred = mask_decoder.predict_masks(image_embedding,image_pe,sparse_prompt_embeddings,dense_prompt_embeddings)\n",
    "print(\"asas\",masks.shape,iou_pred.shape)\n",
    "items = [Item(\"image_embedding\", image_embedding, \"TensorFloat\"), Item(\"image_pe\", image_pe, \"TensorFloat\"), Item(\"sparse_prompt_embeddings\", sparse_prompt_embeddings, \"TensorFloat\"), Item(\"dense_prompt_embeddings\", dense_prompt_embeddings, \"TensorFloat\"), Item(\"masks\", masks, \"TensorFloat\"), Item(\"iou_pred\", iou_pred, \"TensorFloat\")]\n",
    "output_to_file(\"mask_decoder_predict\",items)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28bc7051",
   "metadata": {},
   "source": [
    "## Prompt Encoder\n",
    "#### Positional Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8b6651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.modeling.prompt_encoder import PositionEmbeddingRandom\n",
    "\n",
    "# _pe_encoding \n",
    "position_embedding = PositionEmbeddingRandom(128, None)\n",
    "input_to_file(\"position_embedding_random_pe_encoding\",position_embedding)\n",
    "\n",
    "input = random_tensor([64,2,2],1)\n",
    "output = position_embedding._pe_encoding(input)\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"position_embedding_random_pe_encoding\",items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e34461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward\n",
    "position_embedding = PositionEmbeddingRandom(128, None)\n",
    "input_to_file(\"position_embedding_random_forward\",position_embedding)\n",
    "\n",
    "input= (64,64)\n",
    "output = position_embedding.forward(input)\n",
    "items = [Item(\"input\", input, \"Size\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"position_embedding_random_forward\",items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d43ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward with coords\n",
    "position_embedding = PositionEmbeddingRandom(128, None)\n",
    "input_to_file(\"position_embedding_random_forward_with_coords\",position_embedding)\n",
    "\n",
    "input = random_tensor([64,2,2],1)\n",
    "image_size  = (1024,1024)\n",
    "output = position_embedding.forward_with_coords(input,image_size)\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"image_size\", image_size, \"Size\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"position_embedding_random_forward_with_coords\",items)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74e8b344",
   "metadata": {},
   "source": [
    "#### Prompt Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6762b819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.modeling.prompt_encoder import PromptEncoder\n",
    "\n",
    "mask_in_chans =8\n",
    "embed_dim =128\n",
    "def init_prompt_encoder():\n",
    "    prompt_encoder = PromptEncoder(embed_dim,(32,32),(512,512),mask_in_chans,nn.GELU)\n",
    "    input_to_file(\"prompt_encoder\",prompt_encoder)\n",
    "    return prompt_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f0781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed points\n",
    "prompt_encoder = init_prompt_encoder()\n",
    "\n",
    "points = random_tensor([32,1,2],1)\n",
    "labels = random_tensor([32,1],2)\n",
    "output = prompt_encoder._embed_points(points,labels,True)\n",
    "items = [Item(\"points\", points, \"TensorFloat\"), Item(\"labels\", labels, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"prompt_encoder_embed_points\",items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed70436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed boxes\n",
    "prompt_encoder = init_prompt_encoder()\n",
    "input_to_file(\"prompt_encoder_embed_boxes\",prompt_encoder)\n",
    "\n",
    "boxes = random_tensor([32,1,2],1)\n",
    "output = prompt_encoder._embed_boxes(boxes)\n",
    "items = [Item(\"boxes\", boxes, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"prompt_encoder_embed_boxes\",items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aabc62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Embed masks\n",
    "prompt_encoder = init_prompt_encoder()\n",
    "input_to_file(\"prompt_encoder_embed_masks\",prompt_encoder)\n",
    "\n",
    "masks = random_tensor([8,1,4,4],1)\n",
    "output = prompt_encoder._embed_masks(masks)\n",
    "items = [Item(\"masks\", masks, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"prompt_encoder_embed_masks\",items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709e7f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward \n",
    "prompt_encoder = init_prompt_encoder()\n",
    "input_to_file(\"prompt_encoder_forward\",prompt_encoder)\n",
    "\n",
    "points = random_tensor([8,1,2],1),random_tensor([8,1],2)\n",
    "boxes = None\n",
    "masks = None\n",
    "sparse,dense = prompt_encoder.forward(points,boxes,masks)\n",
    "items = [Item(\"points\", points[0], \"TensorFloat\"),Item(\"labels\", points[1], \"TensorFloat\"), Item(\"sparse\", sparse, \"TensorFloat\"), Item(\"dense\", dense, \"TensorFloat\")]\n",
    "output_to_file(\"prompt_encoder_forward\",items)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "827cddf0",
   "metadata": {},
   "source": [
    "## Utils\n",
    "#### ResizeLongestSide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4527860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.utils.transforms import ResizeLongestSide\n",
    "\n",
    "# Get Preprocess shape\n",
    "resize = ResizeLongestSide(64)\n",
    "output = resize.get_preprocess_shape(32,32,64)\n",
    "items = [Item(\"output\", output, \"Size\")]\n",
    "output_to_file(\"resize_get_preprocess_shape\",items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e257da28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply image\n",
    "resize = ResizeLongestSide(64)\n",
    "input = random_tensor([120,180,3],1).mul(255).type(torch.uint8).numpy()\n",
    "output = resize.apply_image(input)\n",
    "items = [Item(\"input\", input, \"TensorUint8\"), Item(\"output\", output, \"TensorUint8\")]\n",
    "output_to_file(\"resize_apply_image\",items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcde9cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply coords\n",
    "resize = ResizeLongestSide(64)\n",
    "\n",
    "input = random_tensor([1, 2, 2],1).numpy()\n",
    "original_size = (1200,1800)\n",
    "output = resize.apply_coords(input,original_size)\n",
    "items = [Item(\"original_size\", original_size, \"Size\"),Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"resize_apply_coords\",items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6025f76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply boxes\n",
    "resize = ResizeLongestSide(64)\n",
    "\n",
    "boxes=random_tensor([1, 4],1).numpy()\n",
    "original_size = (1200,1800)\n",
    "output = resize.apply_boxes(boxes,original_size)\n",
    "items = [Item(\"original_size\", original_size, \"Size\"),Item(\"boxes\", boxes, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"resize_apply_boxes\",items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e57a115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply image torch\n",
    "resize  = ResizeLongestSide(64)\n",
    "input = random_tensor([1, 3, 32, 32],1)\n",
    "output = resize.apply_image_torch(input)\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"resize_apply_image_torch\",items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1daa58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply coords torch\n",
    "resize  = ResizeLongestSide(64)\n",
    "coords = random_tensor([32,32],1)\n",
    "original_size = (32,32)\n",
    "output = resize.apply_coords_torch(coords,original_size)\n",
    "items = [Item(\"coords\", coords, \"TensorFloat\"), Item(\"original_size\", original_size, \"Size\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"resize_apply_coords_torch\",items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566ae000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply boxes torch\n",
    "resize  = ResizeLongestSide(64)\n",
    "boxes = random_tensor([32,32],1)\n",
    "original_size = (32,32)\n",
    "output = resize.apply_boxes_torch(boxes,original_size)\n",
    "items = [Item(\"boxes\", boxes, \"TensorFloat\"), Item(\"original_size\", original_size, \"Size\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"resize_apply_boxes_torch\",items)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8940f864",
   "metadata": {},
   "source": [
    "## Build Sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20eafa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.build_sam import build_sam_vit_h,Sam,build_sam_vit_b,build_sam_vit_l\n",
    "\n",
    "def get_items(sam:Sam):\n",
    "    items = [\n",
    "        Item(\"mask_threshold\", sam.mask_threshold, \"Float\"),\n",
    "        Item(\"image_format\",sam.image_format, \"String\"),\n",
    "        Item(\"pixel_mean\", sam.pixel_mean, \"TensorFloat\"),\n",
    "        Item(\"pixel_std\", sam.pixel_std, \"TensorFloat\"),\n",
    "        Item(\"mask_decoder.num_mask_tokens\", sam.mask_decoder.num_mask_tokens, \"Int\"),\n",
    "        Item(\"prompt_encoder.embed_dim\", sam.prompt_encoder.embed_dim, \"Int\"),\n",
    "        Item(\"prompt_encoder.input_image_size\", sam.prompt_encoder.input_image_size, \"Size\"),\n",
    "    ]\n",
    "    return items\n",
    "\n",
    "sam_vit_h = build_sam_vit_h()\n",
    "output_to_file(\"sam_vit_h\",get_items(sam_vit_h))\n",
    "\n",
    "sam_vit_b = build_sam_vit_b()\n",
    "output_to_file(\"sam_vit_b\",get_items(sam_vit_b))\n",
    "\n",
    "sam_vit_l = build_sam_vit_l()\n",
    "output_to_file(\"sam_vit_l\",get_items(sam_vit_l))\n",
    "\n",
    "del sam_vit_h, sam_vit_b, sam_vit_l"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55130b9b",
   "metadata": {},
   "source": [
    "## Sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1803455f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init\n",
    "sam = build_sam_test()\n",
    "input_to_file(\"sam_test\",sam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e963fb25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear forward torch.Size([50, 14, 14, 64]) torch.Size([192, 64]) torch.Size([192])\n",
      "Linear forward torch.Size([50, 14, 14, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([2, 64, 64, 64]) torch.Size([256, 64]) torch.Size([256])\n",
      "Linear forward torch.Size([2, 64, 64, 256]) torch.Size([64, 256]) torch.Size([64])\n",
      "Linear forward torch.Size([50, 14, 14, 64]) torch.Size([192, 64]) torch.Size([192])\n",
      "Linear forward torch.Size([50, 14, 14, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([2, 64, 64, 64]) torch.Size([256, 64]) torch.Size([256])\n",
      "Linear forward torch.Size([2, 64, 64, 256]) torch.Size([64, 256]) torch.Size([64])\n",
      "Linear forward torch.Size([2, 64, 64, 64]) torch.Size([192, 64]) torch.Size([192])\n",
      "Linear forward torch.Size([2, 64, 64, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([2, 64, 64, 64]) torch.Size([256, 64]) torch.Size([256])\n",
      "Linear forward torch.Size([2, 64, 64, 256]) torch.Size([64, 256]) torch.Size([64])\n",
      "Linear forward torch.Size([50, 14, 14, 64]) torch.Size([192, 64]) torch.Size([192])\n",
      "Linear forward torch.Size([50, 14, 14, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([2, 64, 64, 64]) torch.Size([256, 64]) torch.Size([256])\n",
      "Linear forward torch.Size([2, 64, 64, 256]) torch.Size([64, 256]) torch.Size([64])\n",
      "Linear forward torch.Size([4, 7, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 7, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 7, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 7, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 7, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([4, 4096, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([4, 4096, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([4, 7, 128]) torch.Size([256, 128]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 7, 256]) torch.Size([2048, 256]) torch.Size([2048])\n",
      "Linear forward torch.Size([4, 7, 2048]) torch.Size([256, 2048]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 4096, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([4, 7, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([4, 7, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([4, 4096, 128]) torch.Size([256, 128]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 7, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 7, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 7, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 7, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 7, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([4, 4096, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([4, 4096, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([4, 7, 128]) torch.Size([256, 128]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 7, 256]) torch.Size([2048, 256]) torch.Size([2048])\n",
      "Linear forward torch.Size([4, 7, 2048]) torch.Size([256, 2048]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 4096, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([4, 7, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([4, 7, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([4, 4096, 128]) torch.Size([256, 128]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 7, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([4, 4096, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([4, 4096, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([4, 7, 128]) torch.Size([256, 128]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 256]) torch.Size([32, 256]) torch.Size([32])\n",
      "Linear forward torch.Size([4, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 256]) torch.Size([32, 256]) torch.Size([32])\n",
      "Linear forward torch.Size([4, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 256]) torch.Size([32, 256]) torch.Size([32])\n",
      "Linear forward torch.Size([4, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 256]) torch.Size([32, 256]) torch.Size([32])\n",
      "Linear forward torch.Size([4, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 256]) torch.Size([4, 256]) torch.Size([4])\n",
      "Linear forward torch.Size([4, 7, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 7, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 7, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 7, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 7, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([4, 4096, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([4, 4096, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([4, 7, 128]) torch.Size([256, 128]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 7, 256]) torch.Size([2048, 256]) torch.Size([2048])\n",
      "Linear forward torch.Size([4, 7, 2048]) torch.Size([256, 2048]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 4096, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([4, 7, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([4, 7, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([4, 4096, 128]) torch.Size([256, 128]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 7, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 7, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 7, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 7, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 7, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([4, 4096, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([4, 4096, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([4, 7, 128]) torch.Size([256, 128]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 7, 256]) torch.Size([2048, 256]) torch.Size([2048])\n",
      "Linear forward torch.Size([4, 7, 2048]) torch.Size([256, 2048]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 4096, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([4, 7, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([4, 7, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([4, 4096, 128]) torch.Size([256, 128]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 7, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([4, 4096, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([4, 4096, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([4, 7, 128]) torch.Size([256, 128]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 256]) torch.Size([32, 256]) torch.Size([32])\n",
      "Linear forward torch.Size([4, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 256]) torch.Size([32, 256]) torch.Size([32])\n",
      "Linear forward torch.Size([4, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 256]) torch.Size([32, 256]) torch.Size([32])\n",
      "Linear forward torch.Size([4, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 256]) torch.Size([32, 256]) torch.Size([32])\n",
      "Linear forward torch.Size([4, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([4, 256]) torch.Size([4, 256]) torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "# Forward\n",
    "sam = build_sam_test()\n",
    "\n",
    "batched_input = [\n",
    "     {\n",
    "         'image': random_tensor([3,8,8],1),\n",
    "         'boxes': random_tensor([4,4],1),\n",
    "         'original_size': (100,200)\n",
    "     },\n",
    "     {\n",
    "         'image': random_tensor([3,8,8],2),\n",
    "         'boxes': random_tensor([4,4],2),\n",
    "         'original_size': (50,80)\n",
    "     }\n",
    "]\n",
    "output = sam.forward(batched_input,False)\n",
    "items=[]\n",
    "i=0\n",
    "for x in output:\n",
    "    masks = x['masks']\n",
    "    items.append(Item(\"masks\"+str(i), masks, \"TensorBool\"))\n",
    "\n",
    "    iou_predictions = x['iou_predictions']\n",
    "    items.append(Item(\"iou_predictions\"+str(i), iou_predictions, \"TensorFloat\"))\n",
    "\n",
    "    if 'low_res_logits' in x:\n",
    "        low_res_masks = x['low_res_logits']\n",
    "        items.append(Item(\"low_res_logits\"+str(i), low_res_masks, \"TensorFloat\"))\n",
    "    i+=1\n",
    "\n",
    "    \n",
    "output_to_file(\"sam_forward\",items)\n",
    "del sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f6e903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postprocess masks\n",
    "sam = build_sam_test()\n",
    "\n",
    "masks = random_tensor([4,1,256,256],1)\n",
    "input_size = (684,1024)\n",
    "original_size = (534,800)\n",
    "output = sam.postprocess_masks(masks,input_size,original_size)\n",
    "items = [Item(\"masks\", masks, \"TensorFloat\"), Item(\"input_size\", input_size, \"Size\"), Item(\"original_size\", original_size, \"Size\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"sam_postprocess_masks\",items)\n",
    "del sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9ae7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "sam = build_sam_test()\n",
    "\n",
    "input = random_tensor([1,3,171,128],1)\n",
    "output = sam.preprocess(input)\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"sam_preprocess\",items)\n",
    "del sam"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16394c79",
   "metadata": {},
   "source": [
    "## Sam Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28df5df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init\n",
    "from segment_anything.predictor import SamPredictor\n",
    "\n",
    "def get_predictor(with_set_image:bool=False):\n",
    "    sam = build_sam_test()\n",
    "    predictor = SamPredictor(sam)\n",
    "    if with_set_image:\n",
    "        image = random_tensor([120,180,3],1).mul(255).type(torch.uint8).numpy()\n",
    "        predictor.set_image(image,\"RGB\")\n",
    "    return predictor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c109a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear forward torch.Size([25, 14, 14, 64]) torch.Size([192, 64]) torch.Size([192])\n",
      "Linear forward torch.Size([25, 14, 14, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([1, 64, 64, 64]) torch.Size([256, 64]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 64, 64, 256]) torch.Size([64, 256]) torch.Size([64])\n",
      "Linear forward torch.Size([25, 14, 14, 64]) torch.Size([192, 64]) torch.Size([192])\n",
      "Linear forward torch.Size([25, 14, 14, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([1, 64, 64, 64]) torch.Size([256, 64]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 64, 64, 256]) torch.Size([64, 256]) torch.Size([64])\n",
      "Linear forward torch.Size([1, 64, 64, 64]) torch.Size([192, 64]) torch.Size([192])\n",
      "Linear forward torch.Size([1, 64, 64, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([1, 64, 64, 64]) torch.Size([256, 64]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 64, 64, 256]) torch.Size([64, 256]) torch.Size([64])\n",
      "Linear forward torch.Size([25, 14, 14, 64]) torch.Size([192, 64]) torch.Size([192])\n",
      "Linear forward torch.Size([25, 14, 14, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([1, 64, 64, 64]) torch.Size([256, 64]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 64, 64, 256]) torch.Size([64, 256]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Set image \n",
    "predictor = get_predictor(True)\n",
    "\n",
    "items=[\n",
    "    Item(\"original_size\",predictor.original_size,\"Size\"),\n",
    "    Item(\"input_size\",predictor.input_size,\"Size\"),\n",
    "    Item(\"features\",predictor.features,\"TensorFloat\"),\n",
    "    Item(\"is_image_set\",predictor.is_image_set,\"Bool\"),\n",
    "]\n",
    "output_to_file(\"predictor_set_image\",items)\n",
    "del predictor,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a85b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear forward torch.Size([25, 14, 14, 64]) torch.Size([192, 64]) torch.Size([192])\n",
      "Linear forward torch.Size([25, 14, 14, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([1, 64, 64, 64]) torch.Size([256, 64]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 64, 64, 256]) torch.Size([64, 256]) torch.Size([64])\n",
      "Linear forward torch.Size([25, 14, 14, 64]) torch.Size([192, 64]) torch.Size([192])\n",
      "Linear forward torch.Size([25, 14, 14, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([1, 64, 64, 64]) torch.Size([256, 64]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 64, 64, 256]) torch.Size([64, 256]) torch.Size([64])\n",
      "Linear forward torch.Size([1, 64, 64, 64]) torch.Size([192, 64]) torch.Size([192])\n",
      "Linear forward torch.Size([1, 64, 64, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([1, 64, 64, 64]) torch.Size([256, 64]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 64, 64, 256]) torch.Size([64, 256]) torch.Size([64])\n",
      "Linear forward torch.Size([25, 14, 14, 64]) torch.Size([192, 64]) torch.Size([192])\n",
      "Linear forward torch.Size([25, 14, 14, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([1, 64, 64, 64]) torch.Size([256, 64]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 64, 64, 256]) torch.Size([64, 256]) torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Set torch image\n",
    "predictor = get_predictor()\n",
    "\n",
    "image = random_tensor([1, 3, 683, 1024],1)\n",
    "original_size = (120, 180)\n",
    "predictor.set_torch_image(image,original_size)\n",
    "items=[\n",
    "    Item(\"original_size\",predictor.original_size,\"Size\"),\n",
    "    Item(\"input_size\",predictor.input_size,\"Size\"),\n",
    "    Item(\"features\",predictor.features,\"TensorFloat\"),\n",
    "    Item(\"is_image_set\",predictor.is_image_set,\"Bool\"),\n",
    "]\n",
    "output_to_file(\"predictor_set_torch_image\",items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4667f824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear forward torch.Size([25, 14, 14, 64]) torch.Size([192, 64]) torch.Size([192])\n",
      "Linear forward torch.Size([25, 14, 14, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([1, 64, 64, 64]) torch.Size([256, 64]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 64, 64, 256]) torch.Size([64, 256]) torch.Size([64])\n",
      "Linear forward torch.Size([25, 14, 14, 64]) torch.Size([192, 64]) torch.Size([192])\n",
      "Linear forward torch.Size([25, 14, 14, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([1, 64, 64, 64]) torch.Size([256, 64]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 64, 64, 256]) torch.Size([64, 256]) torch.Size([64])\n",
      "Linear forward torch.Size([1, 64, 64, 64]) torch.Size([192, 64]) torch.Size([192])\n",
      "Linear forward torch.Size([1, 64, 64, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([1, 64, 64, 64]) torch.Size([256, 64]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 64, 64, 256]) torch.Size([64, 256]) torch.Size([64])\n",
      "Linear forward torch.Size([25, 14, 14, 64]) torch.Size([192, 64]) torch.Size([192])\n",
      "Linear forward torch.Size([25, 14, 14, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([1, 64, 64, 64]) torch.Size([256, 64]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 64, 64, 256]) torch.Size([64, 256]) torch.Size([64])\n",
      "Linear forward torch.Size([1, 7, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 7, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 7, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 7, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 7, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([1, 4096, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([1, 4096, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([1, 7, 128]) torch.Size([256, 128]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 7, 256]) torch.Size([2048, 256]) torch.Size([2048])\n",
      "Linear forward torch.Size([1, 7, 2048]) torch.Size([256, 2048]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 4096, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([1, 7, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([1, 7, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([1, 4096, 128]) torch.Size([256, 128]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 7, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 7, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 7, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 7, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 7, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([1, 4096, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([1, 4096, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([1, 7, 128]) torch.Size([256, 128]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 7, 256]) torch.Size([2048, 256]) torch.Size([2048])\n",
      "Linear forward torch.Size([1, 7, 2048]) torch.Size([256, 2048]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 4096, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([1, 7, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([1, 7, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([1, 4096, 128]) torch.Size([256, 128]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 7, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([1, 4096, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([1, 4096, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([1, 7, 128]) torch.Size([256, 128]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 256]) torch.Size([32, 256]) torch.Size([32])\n",
      "Linear forward torch.Size([1, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 256]) torch.Size([32, 256]) torch.Size([32])\n",
      "Linear forward torch.Size([1, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 256]) torch.Size([32, 256]) torch.Size([32])\n",
      "Linear forward torch.Size([1, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 256]) torch.Size([32, 256]) torch.Size([32])\n",
      "Linear forward torch.Size([1, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 256]) torch.Size([4, 256]) torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "predictor = get_predictor(True)\n",
    "\n",
    "point_coords = random_ndarray([1,2],1)\n",
    "point_labels = random_tensor([1],1).mul(255).type(torch.int).numpy()\n",
    "\n",
    "masks, iou_predictions, low_res_masks =predictor.predict(point_coords,point_labels,None,None,True,False)\n",
    "items =[\n",
    "    Item(\"masks\", masks, \"TensorBool\"),\n",
    "    Item(\"iou_predictions\", iou_predictions, \"TensorFloat\"),\n",
    "    Item(\"low_res_masks\", low_res_masks, \"TensorFloat\"),\n",
    "]\n",
    "output_to_file(\"predictor_predict\",items)\n",
    "del point_coords, point_labels, masks, iou_predictions, low_res_masks,predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62c1a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear forward torch.Size([25, 14, 14, 64]) torch.Size([192, 64]) torch.Size([192])\n",
      "Linear forward torch.Size([25, 14, 14, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([1, 64, 64, 64]) torch.Size([256, 64]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 64, 64, 256]) torch.Size([64, 256]) torch.Size([64])\n",
      "Linear forward torch.Size([25, 14, 14, 64]) torch.Size([192, 64]) torch.Size([192])\n",
      "Linear forward torch.Size([25, 14, 14, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([1, 64, 64, 64]) torch.Size([256, 64]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 64, 64, 256]) torch.Size([64, 256]) torch.Size([64])\n",
      "Linear forward torch.Size([1, 64, 64, 64]) torch.Size([192, 64]) torch.Size([192])\n",
      "Linear forward torch.Size([1, 64, 64, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([1, 64, 64, 64]) torch.Size([256, 64]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 64, 64, 256]) torch.Size([64, 256]) torch.Size([64])\n",
      "Linear forward torch.Size([25, 14, 14, 64]) torch.Size([192, 64]) torch.Size([192])\n",
      "Linear forward torch.Size([25, 14, 14, 64]) torch.Size([64, 64]) torch.Size([64])\n",
      "Linear forward torch.Size([1, 64, 64, 64]) torch.Size([256, 64]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 64, 64, 256]) torch.Size([64, 256]) torch.Size([64])\n",
      "Linear forward torch.Size([1, 7, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 7, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 7, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 7, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 7, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([1, 4096, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([1, 4096, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([1, 7, 128]) torch.Size([256, 128]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 7, 256]) torch.Size([2048, 256]) torch.Size([2048])\n",
      "Linear forward torch.Size([1, 7, 2048]) torch.Size([256, 2048]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 4096, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([1, 7, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([1, 7, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([1, 4096, 128]) torch.Size([256, 128]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 7, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 7, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 7, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 7, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 7, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([1, 4096, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([1, 4096, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([1, 7, 128]) torch.Size([256, 128]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 7, 256]) torch.Size([2048, 256]) torch.Size([2048])\n",
      "Linear forward torch.Size([1, 7, 2048]) torch.Size([256, 2048]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 4096, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([1, 7, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([1, 7, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([1, 4096, 128]) torch.Size([256, 128]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 7, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([1, 4096, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([1, 4096, 256]) torch.Size([128, 256]) torch.Size([128])\n",
      "Linear forward torch.Size([1, 7, 128]) torch.Size([256, 128]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 256]) torch.Size([32, 256]) torch.Size([32])\n",
      "Linear forward torch.Size([1, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 256]) torch.Size([32, 256]) torch.Size([32])\n",
      "Linear forward torch.Size([1, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 256]) torch.Size([32, 256]) torch.Size([32])\n",
      "Linear forward torch.Size([1, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 256]) torch.Size([32, 256]) torch.Size([32])\n",
      "Linear forward torch.Size([1, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 256]) torch.Size([256, 256]) torch.Size([256])\n",
      "Linear forward torch.Size([1, 256]) torch.Size([4, 256]) torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "# Predict torch\n",
    "predictor = get_predictor(True)\n",
    "\n",
    "point_coords = random_tensor([1,1,2],1)\n",
    "point_labels = random_tensor([1,1],1)\n",
    "masks, iou_predictions, low_res_masks = predictor.predict_torch(point_coords,point_labels,None,None,True,False)\n",
    "items =[\n",
    "    Item(\"masks\", masks, \"TensorBool\"),\n",
    "    Item(\"iou_predictions\", iou_predictions, \"TensorFloat\"),\n",
    "    Item(\"low_res_masks\", low_res_masks, \"TensorFloat\")\n",
    "]\n",
    "output_to_file(\"predictor_predict_torch\",items)\n",
    "del predictor,point_coords,point_labels,masks,iou_predictions,low_res_masks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
