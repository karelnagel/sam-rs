{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ad3bf14",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04ec4816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Item:\n",
    "    def __init__(self, key, value, type:str):\n",
    "        self.key = key\n",
    "        self.type = type\n",
    "        if type.startswith(\"Tensor\"):\n",
    "            self.value = {\"size\":value.size(),\"values\":value.flatten().tolist()}\n",
    "        else:\n",
    "            self.value = value\n",
    "\n",
    "    def to_dict(self):\n",
    "        return {self.key: {self.type: self.value}}\n",
    "\n",
    "\n",
    "def to_file(name:str,items:list):\n",
    "    path = \"test-files/\"+name+\".json\"\n",
    "    values = {}\n",
    "    for item in items:\n",
    "        values.update(item.to_dict())\n",
    "    output = {\"values\": values}\n",
    "    \n",
    "    data = json.dumps(output, indent=4)\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, \"w\") as f:\n",
    "        f.write(data)\n",
    "\n",
    "def random_tensor(shape:list,seed:int=0):\n",
    "    n = 1 \n",
    "    for dim in shape:\n",
    "        n*=dim\n",
    "\n",
    "    a = 3\n",
    "    c = 23\n",
    "    m = 2**32\n",
    "    \n",
    "    result = []\n",
    "    x = seed\n",
    "    for _ in range(n):\n",
    "        x = (a * x + c) % m\n",
    "        result.append(x / m)  # Normalize the result to [0, 1]\n",
    "\n",
    "    return torch.tensor(result).view(shape)\n",
    "\n",
    "def mock_linear(linear:nn.Linear )->nn.Linear:\n",
    "    linear.weight.data = random_tensor(linear.weight.size(),1)\n",
    "    linear.bias.data = random_tensor(linear.bias.size(),2)\n",
    "\n",
    "def mock_layer_norm(layer_norm: nn.LayerNorm)->nn.LayerNorm:\n",
    "    layer_norm.weight.data = random_tensor(layer_norm.weight.size(),1)\n",
    "    layer_norm.bias.data = random_tensor(layer_norm.bias.size(),2)\n",
    "\n",
    "def mock_conv2d(conv2d:nn.Conv2d)->nn.Conv2d:\n",
    "    conv2d.weight.data = random_tensor(conv2d.weight.size(),1)\n",
    "    conv2d.bias.data = random_tensor(conv2d.bias.size(),2)\n",
    "\n",
    "def mock_embedding(embedding:nn.Embedding)->nn.Embedding:\n",
    "    embedding.weight.data = random_tensor(embedding.weight.size(),1)\n",
    "\n",
    "def mock_conv_transpose2d(conv: nn.ConvTranspose2d)->nn.ConvTranspose2d:\n",
    "    conv.weight.data = random_tensor(conv.weight.size(),1)\n",
    "    conv.bias.data = random_tensor(conv.bias.size(),2)\n",
    "\n",
    "def mock_tensor(tensor:torch.Tensor)->torch.Tensor:\n",
    "    tensor.data = random_tensor(tensor.size(),1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0efaef2",
   "metadata": {},
   "source": [
    "## Common\n",
    "#### LayerNorm2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f813cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.modeling.common import LayerNorm2d\n",
    "\n",
    "layer_norm = LayerNorm2d(256,0.1)\n",
    "items = [Item(\"weight\", layer_norm.weight, \"TensorFloat\"), Item(\"bias\", layer_norm.bias, \"TensorFloat\"), Item(\"eps\", layer_norm.eps, \"Float\")]\n",
    "to_file(\"layer_norm_2d\",items)\n",
    "\n",
    "# Forward\n",
    "input = random_tensor([2,256,16,16])\n",
    "output = layer_norm(input)\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "to_file(\"layer_norm_2d_forward\",items)\n",
    "del layer_norm, input, output,items"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6a99864",
   "metadata": {},
   "source": [
    "#### MLPBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6867373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.modeling.common import MLPBlock\n",
    "\n",
    "mlp_block = MLPBlock(256,256,nn.GELU)\n",
    "items=[Item(\"lin1_size\", mlp_block.lin1.weight.size(), \"List\"), Item(\"lin2_size\", mlp_block.lin2.weight.size(), \"List\")]\n",
    "to_file(\"mlp_block\",items)\n",
    "\n",
    "#Mocking \n",
    "def mock_mlp_block(mlp_block:MLPBlock)->MLPBlock:\n",
    "    mock_linear(mlp_block.lin1)\n",
    "    mock_linear(mlp_block.lin2)\n",
    "mock_mlp_block(mlp_block)\n",
    "\n",
    "# Forward\n",
    "input = random_tensor([256,256],5)\n",
    "output = mlp_block(input)\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "to_file(\"mlp_block_forward\",items)\n",
    "del mlp_block, input, output,items"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cad0ddd8",
   "metadata": {},
   "source": [
    "#### Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39781f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gelu\n",
    "gelu = nn.GELU()\n",
    "input = random_tensor([256,256])\n",
    "output = gelu(input)\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "to_file(\"activation_gelu\",items)\n",
    "\n",
    "# ReLU\n",
    "relu = nn.ReLU()\n",
    "input = random_tensor([256,256])\n",
    "output = relu(input)\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "to_file(\"activation_relu\",items)\n",
    "del input,output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74fade84",
   "metadata": {},
   "source": [
    "# Image encoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56f80aac",
   "metadata": {},
   "source": [
    "#### PatchEmbeded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08dd2d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.modeling.image_encoder import PatchEmbed\n",
    "\n",
    "patch_embed = PatchEmbed((16,16),(16,16),(0,0),3,320)\n",
    "items=[Item(\"proj_size\", patch_embed.proj.weight.size(), \"List\")]\n",
    "to_file(\"patch_embed\",items)\n",
    "\n",
    "# Mocking \n",
    "def mock_patch_embed(patch_embed:PatchEmbed)->PatchEmbed:\n",
    "    mock_conv2d(patch_embed.proj)\n",
    "mock_patch_embed(patch_embed)\n",
    "\n",
    "# Forward\n",
    "input = random_tensor([1,3,512,512],3)\n",
    "output = patch_embed(input)\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "to_file(\"patch_embed_forward\",items)\n",
    "del patch_embed, input, output,items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0abc93",
   "metadata": {},
   "source": [
    "#### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8241be48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.modeling.image_encoder import get_rel_pos,add_decomposed_rel_pos\n",
    "\n",
    "# Get rel pos\n",
    "q_size = 32\n",
    "k_size = 32\n",
    "input = random_tensor([127,40],1)\n",
    "output = get_rel_pos( q_size, k_size, input)\n",
    "items = [Item(\"input\",input,\"TensorFloat\"),Item(\"output\", output, \"TensorFloat\")]\n",
    "to_file(\"get_rel_pos\",items)\n",
    "del input, output\n",
    "\n",
    "\n",
    "# Add decomposed rel pos\n",
    "attn = random_tensor([200,49,49],2)\n",
    "q = random_tensor([200,49,20],3)\n",
    "relo_pos_h = random_tensor([20,20],4)\n",
    "relo_pos_w = random_tensor([20,20],5)\n",
    "q_size = (7,7)\n",
    "k_size = (7,7)\n",
    "output = add_decomposed_rel_pos(attn,q,relo_pos_h,relo_pos_w,q_size,k_size)\n",
    "items = [Item(\"attn\", attn, \"TensorFloat\"), Item(\"q\", q, \"TensorFloat\"), Item(\"q_size\", q_size, \"Size\"), Item(\"k_size\", k_size, \"Size\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "to_file(\"add_decomposed_rel_pos\",items)\n",
    "del attn,q,relo_pos_h,relo_pos_w,q_size,k_size,output,items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "825bf833",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.modeling.image_encoder import Attention\n",
    "\n",
    "# Attention\n",
    "attention = Attention(320, 16 ,True ,True ,True, (14, 14))\n",
    "items =[Item(\"num_heads\", attention.num_heads, \"Int\"), Item(\"scale\", attention.scale, \"Float\"),  Item(\"use_rel_pos\", attention.use_rel_pos, \"Bool\")]\n",
    "to_file(\"attention\",items)\n",
    "\n",
    "#Mocking \n",
    "def mock_attention(attention:Attention)->Attention:\n",
    "    mock_linear(attention.qkv)\n",
    "    mock_linear(attention.proj)\n",
    "mock_attention(attention)\n",
    "\n",
    "# Forward\n",
    "input = random_tensor([25,14,14,320],1)\n",
    "output = attention(input)\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "to_file(\"attention_forward\",items)\n",
    "del input\n",
    "del output\n",
    "del attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d09b671",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.modeling.image_encoder import  window_partition,window_unpartition\n",
    "\n",
    "# Window partition\n",
    "input = random_tensor([2,256,16,16],1)\n",
    "output,size = window_partition(input,16)\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\"), Item(\"size\", size, \"Size\")]\n",
    "to_file(\"window_partition\",items)\n",
    "\n",
    "# Window unpartition\n",
    "input = random_tensor([2,256,16,16],2)\n",
    "output = window_unpartition(input,16,(16,16),(14,14))\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "to_file(\"window_unpartition\",items)\n",
    "del input, output, items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38040f69",
   "metadata": {},
   "source": [
    "#### Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ba0e9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.modeling.image_encoder import Block\n",
    "\n",
    "#Block\n",
    "block = Block(320,16,4.0,True,nn.LayerNorm,nn.GELU,True,True,14,(64,64))\n",
    "items=[Item(\"window_size\", block.window_size, \"Int\")]\n",
    "to_file(\"block\",items)\n",
    "\n",
    "#Mocking \n",
    "def mock_block(block:Block)->Block:\n",
    "    mock_layer_norm(block.norm1)\n",
    "    mock_layer_norm(block.norm2)\n",
    "    mock_attention(block.attn)\n",
    "    mock_mlp_block(block.mlp )\n",
    "mock_block(block)\n",
    "#Forward\n",
    "input = random_tensor([1,64,64,320],1)\n",
    "output = block(input)\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "to_file(\"block_forward\",items)\n",
    "del block, input, output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4e1c390",
   "metadata": {},
   "source": [
    "#### Image encoderViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83369d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.modeling.image_encoder import ImageEncoderViT\n",
    "\n",
    "image_encoder = ImageEncoderViT(128,4,3,320,32,16,4.0,256,True,nn.LayerNorm,nn.GELU,True,True,True,14,[7,15,23,31])\n",
    "items =[Item(\"img_size\", image_encoder.img_size,\"Int\")]\n",
    "to_file(\"image_encoder\",items)\n",
    "\n",
    "input = random_tensor([1,3,128,128],1)\n",
    "output = image_encoder(input)\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "to_file(\"image_encoder_forward\",items)\n",
    "\n",
    "del image_encoder\n",
    "del input\n",
    "del output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66c6f570",
   "metadata": {},
   "source": [
    "## Transformer\n",
    "#### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee398610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.modeling.transformer import Attention\n",
    "\n",
    "attention = Attention(256,8,1)\n",
    "items = [Item(\"embedding_dim\", attention.embedding_dim, \"Int\"),\n",
    "          Item(\"internal_dim\", attention.internal_dim, \"Int\"),\n",
    "          Item(\"num_heads\", attention.num_heads, \"Int\"),\n",
    "          Item(\"q_proj_size\", attention.q_proj.weight.size(), \"List\"),\n",
    "          Item(\"k_proj_size\", attention.k_proj.weight.size(), \"List\"),\n",
    "          Item(\"v_proj_size\", attention.v_proj.weight.size(), \"List\"),\n",
    "          Item(\"out_proj_size\", attention.out_proj.weight.size(), \"List\"),]\n",
    "to_file(\"transformer_attention\",items)\n",
    "\n",
    "#Mocking\n",
    "def mock_transformer_attention(attention:Attention)->Attention:\n",
    "    mock_linear(attention.q_proj)\n",
    "    mock_linear(attention.k_proj)\n",
    "    mock_linear(attention.v_proj)\n",
    "    mock_linear(attention.out_proj)\n",
    "mock_transformer_attention(attention)\n",
    "\n",
    "#Forward\n",
    "q = random_tensor([1,256,256],1)\n",
    "k = random_tensor([1,256,256],2)\n",
    "v = random_tensor([1,256,256],3)\n",
    "output = attention.forward(q,k,v)\n",
    "items = [Item(\"q\", q, \"TensorFloat\"), Item(\"k\", k, \"TensorFloat\"), Item(\"v\", v, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "to_file(\"transformer_attention_forward\",items)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c1c5c01",
   "metadata": {},
   "source": [
    "#### TwoWayAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48ea625b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.modeling.transformer import TwoWayAttentionBlock\n",
    "\n",
    "block = TwoWayAttentionBlock(256,8,2048,nn.ReLU,2,False)\n",
    "items = [\n",
    "    Item(\"norm1_size\", block.norm1.weight.size(), \"List\"),\n",
    "    Item(\"norm2_size\", block.norm2.weight.size(), \"List\"),\n",
    "    Item(\"norm3_size\", block.norm3.weight.size(), \"List\"),\n",
    "    Item(\"norm4_size\", block.norm4.weight.size(), \"List\"),\n",
    "    Item(\"skip_first_layer_pe\", block.skip_first_layer_pe, \"Bool\"),\n",
    "]\n",
    "to_file(\"transformer_two_way_attention_block\",items)\n",
    "\n",
    "#Mocking\n",
    "def mock_transformer_two_way_attention_block(block:TwoWayAttentionBlock)->TwoWayAttentionBlock:\n",
    "    mock_layer_norm(block.norm1)\n",
    "    mock_layer_norm(block.norm2)\n",
    "    mock_layer_norm(block.norm3)\n",
    "    mock_layer_norm(block.norm4)\n",
    "    mock_transformer_attention(block.cross_attn_image_to_token)\n",
    "    mock_transformer_attention(block.cross_attn_token_to_image)\n",
    "    mock_transformer_attention(block.self_attn)\n",
    "    mock_mlp_block(block.mlp)\n",
    "mock_transformer_two_way_attention_block(block)\n",
    "\n",
    "#Forward\n",
    "queries = random_tensor([1,256,256],1)\n",
    "keys = random_tensor([1,256,256],2)\n",
    "query_pe = random_tensor([1,256,256],3)\n",
    "key_pe = random_tensor([1,256,256],4)\n",
    "out_queries,out_keys = block(queries,keys,query_pe,key_pe)\n",
    "items = [Item(\"queries\", queries, \"TensorFloat\"), Item(\"keys\", keys, \"TensorFloat\"), Item(\"query_pe\", query_pe, \"TensorFloat\"), Item(\"key_pe\", key_pe, \"TensorFloat\"), Item(\"out_queries\", out_queries, \"TensorFloat\"), Item(\"out_keys\", out_keys, \"TensorFloat\")]\n",
    "to_file(\"transformer_two_way_attention_block_forward\",items)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3168b933",
   "metadata": {},
   "source": [
    "#### TwoWayTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a7fa73fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.modeling.transformer import TwoWayTransformer\n",
    "\n",
    "transformer = TwoWayTransformer(2, 64, 4, 256, nn.ReLU, 2)\n",
    "items =[\n",
    "    Item(\"depth\", transformer.depth, \"Int\"),\n",
    "    Item(\"embedding_dim\", transformer.embedding_dim, \"Int\"),\n",
    "    Item(\"num_heads\", transformer.num_heads, \"Int\"),\n",
    "    Item(\"mlp_dim\", transformer.mlp_dim, \"Int\"),\n",
    "    Item(\"layers_len\", len(transformer.layers), \"Int\"),\n",
    "]\n",
    "to_file(\"transformer_two_way_transformer\",items)\n",
    "\n",
    "# Mocking\n",
    "def mock_transformer_two_way_transformer(transformer:TwoWayTransformer)->TwoWayTransformer:\n",
    "    for i in range(len(transformer.layers)):\n",
    "        mock_transformer_two_way_attention_block(transformer.layers[i])\n",
    "    mock_transformer_attention(transformer.final_attn_token_to_image)\n",
    "    mock_layer_norm(transformer.norm_final_attn)\n",
    "mock_transformer_two_way_transformer(transformer)\n",
    "\n",
    "# Forward\n",
    "\n",
    "image_embedding = random_tensor([1,64,16,16],1)\n",
    "image_pe = random_tensor([1,64,16,16],2)\n",
    "point_embedding = random_tensor([16, 256, 64],3)\n",
    "queries,keys = transformer(image_embedding,image_pe,point_embedding)\n",
    "items = [Item(\"image_embedding\", image_embedding, \"TensorFloat\"), Item(\"image_pe\", image_pe, \"TensorFloat\"), Item(\"point_embedding\", point_embedding, \"TensorFloat\"), Item(\"queries\", queries, \"TensorFloat\"), Item(\"keys\", keys, \"TensorFloat\")]\n",
    "to_file(\"transformer_two_way_transformer_forward\",items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d5a673",
   "metadata": {},
   "source": [
    "## Mask decoder\n",
    "#### MLP block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a847818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.modeling.mask_decoder import MLP\n",
    "\n",
    "mlp = MLP(256,256,256,4,False)\n",
    "items = [Item(\"num_layers\", mlp.num_layers, \"Int\"), Item(\"sigmoid_output\", mlp.sigmoid_output, \"Bool\"), Item(\"layers_len\",len(mlp.layers),\"Int\")]\n",
    "for i in range(len(mlp.layers)):\n",
    "    items.append(Item(\"layer\"+str(i), mlp.layers[i].weight.size(), \"List\"))\n",
    "to_file(\"mlp\",items)\n",
    "\n",
    "# Mocking\n",
    "def mock_mlp(mlp:MLP)->MLP:\n",
    "    for i in range(len(mlp.layers)):\n",
    "        mock_linear(mlp.layers[i])\n",
    "mock_mlp(mlp)\n",
    "# Forward\n",
    "input = random_tensor([1,256],1)\n",
    "output = mlp(input)\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "to_file(\"mlp_forward\",items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "088e4ce7",
   "metadata": {},
   "source": [
    "#### Mask decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f75fa9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.modeling.mask_decoder import MaskDecoder\n",
    "\n",
    "transformer = TwoWayTransformer(2, 64, 2, 512, nn.ReLU, 2)\n",
    "mask_decoder = MaskDecoder(transformer_dim=64,transformer=transformer,num_multimask_outputs=3, activation=nn.GELU,iou_head_depth=3,iou_head_hidden_dim=64)\n",
    "items = [\n",
    "    Item(\"transformer_dim\", mask_decoder.transformer_dim, \"Int\"),\n",
    "    Item(\"num_multimask_outputs\", mask_decoder.num_multimask_outputs, \"Int\"),\n",
    "    Item(\"num_mask_tokens\", mask_decoder.num_mask_tokens, \"Int\"),\n",
    "]\n",
    "to_file(\"mask_decoder\",items)\n",
    "\n",
    "# Mocking\n",
    "def mock_mask_decoder(mask_decoder:MaskDecoder)->MaskDecoder:\n",
    "    mock_transformer_two_way_transformer(mask_decoder.transformer)\n",
    "    mock_embedding(mask_decoder.iou_token)\n",
    "    mock_embedding(mask_decoder.mask_tokens)\n",
    "    for i in range(len(mask_decoder.output_hypernetworks_mlps)):\n",
    "        mock_mlp(mask_decoder.output_hypernetworks_mlps[i])\n",
    "    mock_mlp(mask_decoder.iou_prediction_head)\n",
    "    conv = nn.ConvTranspose2d(mask_decoder.transformer_dim, mask_decoder.transformer_dim // 4, kernel_size=2, stride=2)\n",
    "    conv2 = nn.ConvTranspose2d(mask_decoder.transformer_dim // 4, mask_decoder.transformer_dim // 8, kernel_size=2, stride=2)\n",
    "    mock_conv_transpose2d(conv)\n",
    "    mock_conv_transpose2d(conv2)\n",
    "    mask_decoder.output_upscaling = nn.Sequential(\n",
    "            conv,\n",
    "            LayerNorm2d(mask_decoder.transformer_dim // 4),\n",
    "            nn.GELU(),\n",
    "            conv2,\n",
    "            nn.GELU(),\n",
    "        )\n",
    "mock_mask_decoder(mask_decoder)\n",
    "\n",
    "# Forward\n",
    "image_embedding = random_tensor([1,64,16,16],1)\n",
    "image_pe = random_tensor([1,64,16,16],2)\n",
    "sparse_prompt_embeddings = random_tensor([16, 2, 64],3)\n",
    "dense_prompt_embeddings = random_tensor([16, 64, 16, 16],4)\n",
    "masks, iou_pred = mask_decoder(image_embedding,image_pe,sparse_prompt_embeddings,dense_prompt_embeddings,True)\n",
    "items = [Item(\"image_embedding\", image_embedding, \"TensorFloat\"), Item(\"image_pe\", image_pe, \"TensorFloat\"), Item(\"sparse_prompt_embeddings\", sparse_prompt_embeddings, \"TensorFloat\"), Item(\"dense_prompt_embeddings\", dense_prompt_embeddings, \"TensorFloat\"), Item(\"masks\", masks, \"TensorFloat\"), Item(\"iou_pred\", iou_pred, \"TensorFloat\")]\n",
    "to_file(\"mask_decoder_forward\",items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4a404f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict masks\n",
    "transformer = TwoWayTransformer(2, 64, 2, 512, nn.ReLU, 2)\n",
    "mask_decoder = MaskDecoder(transformer_dim=64,transformer=transformer,num_multimask_outputs=3, activation=nn.GELU,iou_head_depth=3,iou_head_hidden_dim=64)\n",
    "\n",
    "# Mocking\n",
    "mock_mask_decoder(mask_decoder)\n",
    "\n",
    "# Predict masks\n",
    "image_embedding = random_tensor([1,64,16,16],1)\n",
    "image_pe = random_tensor([1,64,16,16],2)\n",
    "sparse_prompt_embeddings = random_tensor([16, 2, 64],3)\n",
    "dense_prompt_embeddings = random_tensor([16, 64, 16, 16],4)\n",
    "masks, iou_pred = mask_decoder.predict_masks(image_embedding,image_pe,sparse_prompt_embeddings,dense_prompt_embeddings)\n",
    "items = [Item(\"image_embedding\", image_embedding, \"TensorFloat\"), Item(\"image_pe\", image_pe, \"TensorFloat\"), Item(\"sparse_prompt_embeddings\", sparse_prompt_embeddings, \"TensorFloat\"), Item(\"dense_prompt_embeddings\", dense_prompt_embeddings, \"TensorFloat\"), Item(\"masks\", masks, \"TensorFloat\"), Item(\"iou_pred\", iou_pred, \"TensorFloat\")]\n",
    "to_file(\"mask_decoder_predict\",items)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28bc7051",
   "metadata": {},
   "source": [
    "## Prompt Encoder\n",
    "#### Positional Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc5d3378",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.modeling.prompt_encoder import PositionEmbeddingRandom\n",
    "\n",
    "position_embedding = PositionEmbeddingRandom(128, None)\n",
    "items = [Item(\"gaussian_matrix\", position_embedding.positional_encoding_gaussian_matrix.size(), \"List\")]\n",
    "to_file(\"position_embedding_random\",items)\n",
    "\n",
    "def mock_position_embedding_random(position_embedding:PositionEmbeddingRandom)->PositionEmbeddingRandom:\n",
    "    mock_tensor(position_embedding.positional_encoding_gaussian_matrix)\n",
    "mock_position_embedding_random(position_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bf8b6651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _pe_encoding \n",
    "position_embedding = PositionEmbeddingRandom(128, None)\n",
    "mock_position_embedding_random(position_embedding)\n",
    "\n",
    "input = random_tensor([64,2,2],1)\n",
    "output = position_embedding._pe_encoding(input)\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "to_file(\"position_embedding_random_pe_encoding\",items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9e34461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward\n",
    "position_embedding = PositionEmbeddingRandom(128, None)\n",
    "mock_position_embedding_random(position_embedding)\n",
    "\n",
    "input= (64,64)\n",
    "output = position_embedding.forward(input)\n",
    "items = [Item(\"input\", input, \"Size\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "to_file(\"position_embedding_random_forward\",items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12d43ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward with coords\n",
    "position_embedding = PositionEmbeddingRandom(128, None)\n",
    "mock_position_embedding_random(position_embedding)\n",
    "\n",
    "input = random_tensor([64,2,2],1)\n",
    "image_size  = (1024,1024)\n",
    "output = position_embedding.forward_with_coords(input,image_size)\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"image_size\", image_size, \"Size\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "to_file(\"position_embedding_random_forward_with_coords\",items)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74e8b344",
   "metadata": {},
   "source": [
    "#### Prompt Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6762b819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.modeling.prompt_encoder import PromptEncoder\n",
    "\n",
    "mask_in_chans =16\n",
    "embed_dim =256\n",
    "prompt_encoder = PromptEncoder(256,(64,64),(1024,1024),mask_in_chans,nn.GELU)\n",
    "\n",
    "items = [\n",
    "    Item(\"embed_dim\", prompt_encoder.embed_dim, \"Int\"), \n",
    "    Item(\"input_image_size\", prompt_encoder.input_image_size, \"Size\"), \n",
    "    Item(\"image_embedding_size\", prompt_encoder.image_embedding_size, \"Size\"),\n",
    "    Item(\"num_point_embeddings\", prompt_encoder.num_point_embeddings, \"Int\"),\n",
    "    Item(\"mask_input_size\", prompt_encoder.mask_input_size, \"Size\"),\n",
    "    ]\n",
    "to_file(\"prompt_encoder\",items)\n",
    "\n",
    "def mock_prompt_encoder(encoder:PromptEncoder):\n",
    "    mock_position_embedding_random(encoder.pe_layer)\n",
    "    for i in range(len(encoder.point_embeddings)):\n",
    "        mock_embedding(encoder.point_embeddings[i])\n",
    "    mock_embedding(encoder.no_mask_embed)\n",
    "    mock_embedding(encoder.not_a_point_embed)\n",
    "    conv1 = nn.Conv2d(1, mask_in_chans // 4, kernel_size=2, stride=2)\n",
    "    conv2 = nn.Conv2d(mask_in_chans // 4, mask_in_chans, kernel_size=2, stride=2)\n",
    "    conv3 = nn.Conv2d(mask_in_chans, embed_dim, kernel_size=1)\n",
    "    mock_conv2d(conv1)\n",
    "    mock_conv2d(conv2)\n",
    "    mock_conv2d(conv3)\n",
    "    encoder.mask_downscaling = nn.Sequential(\n",
    "            conv1,\n",
    "            LayerNorm2d(mask_in_chans // 4),\n",
    "            nn.GELU(),\n",
    "            conv2,\n",
    "            LayerNorm2d(mask_in_chans),\n",
    "            nn.GELU(),\n",
    "            conv3,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42f0781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed points\n",
    "prompt_encoder = PromptEncoder(256,(64,64),(1024,1024),mask_in_chans,nn.GELU)\n",
    "mock_prompt_encoder(prompt_encoder)\n",
    "\n",
    "points = random_tensor([64,1,2],1)\n",
    "labels = random_tensor([64,1],2)\n",
    "output = prompt_encoder._embed_points(points,labels,True)\n",
    "items = [Item(\"points\", points, \"TensorFloat\"), Item(\"labels\", labels, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "to_file(\"prompt_encoder_embed_points\",items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed70436b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2, 256]) torch.Size([1, 256]) torch.Size([1, 256])\n",
      "torch.Size([32, 2, 256])\n"
     ]
    }
   ],
   "source": [
    "# Embed boxes\n",
    "prompt_encoder = PromptEncoder(256,(64,64),(1024,1024),mask_in_chans,nn.GELU)\n",
    "mock_prompt_encoder(prompt_encoder)\n",
    "\n",
    "boxes = random_tensor([64,1,2],1)\n",
    "output = prompt_encoder._embed_boxes(boxes)\n",
    "items = [Item(\"boxes\", boxes, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "to_file(\"prompt_encoder_embed_boxes\",items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Embed masks\n",
    "# prompt_encoder = PromptEncoder(256,(64,64),(1024,1024),mask_in_chans,nn.GELU)\n",
    "# mock_prompt_encoder(prompt_encoder)\n",
    "\n",
    "# masks = random_tensor([2,2,2,1],1)\n",
    "# output = prompt_encoder._embed_masks(masks)\n",
    "# items = [Item(\"masks\", masks, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "# to_file(\"prompt_encoder_embed_masks\",items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "709e7f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward \n",
    "prompt_encoder = PromptEncoder(256,(64,64),(1024,1024),mask_in_chans,nn.GELU)\n",
    "mock_prompt_encoder(prompt_encoder)\n",
    "\n",
    "points = random_tensor([16,1,2],1),random_tensor([16,1],2)\n",
    "boxes = None\n",
    "masks = None\n",
    "sparse,dense = prompt_encoder.forward(points,boxes,masks)\n",
    "items = [Item(\"points\", points[0], \"TensorFloat\"),Item(\"labels\", points[1], \"TensorFloat\"), Item(\"sparse\", sparse, \"TensorFloat\"), Item(\"dense\", dense, \"TensorFloat\")]\n",
    "to_file(\"prompt_encoder_forward\",items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06eae295",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4f3eb8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 2, 256])\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "labels = torch.rand([16,2])\n",
    "point_embeddings = nn.Embedding(1, 256), nn.Embedding(1, 256)\n",
    "not_a_point_embed = nn.Embedding(1, 256)\n",
    "\n",
    "val1 = random_tensor([16,2,256],1)\n",
    "val1[labels == -1] = 0.0\n",
    "val1[labels == -1] += not_a_point_embed.weight\n",
    "val1[labels == 0] += point_embeddings[0].weight\n",
    "val1[labels == 1] += point_embeddings[1].weight\n",
    "print(val1.shape) # torch.Size([16, 2, 256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3ba6f971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 2, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val2 = random_tensor([16,2,256],1)\n",
    "# Create masks for each condition\n",
    "mask_minus_one = labels.eq(-1)\n",
    "mask_zero = labels.eq(0)\n",
    "mask_one = labels.eq(1)\n",
    "\n",
    "# Update point_embedding based on the masks\n",
    "val2 = torch.where(mask_minus_one.unsqueeze(-1), torch.zeros_like(val2), val2)\n",
    "val2 = torch.where(mask_minus_one.unsqueeze(-1), val2 + not_a_point_embed.weight, val2)\n",
    "val2 = torch.where(mask_zero.unsqueeze(-1), val2 + point_embeddings[0].weight, val2)\n",
    "val2 = torch.where(mask_one.unsqueeze(-1), val2 + point_embeddings[1].weight, val2)\n",
    "print(val2.shape) # torch.Size([16, 2, 256])\n",
    "torch.equal(val1,val2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3a934ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2, 256])\n"
     ]
    }
   ],
   "source": [
    "corner_embedding = random_tensor([32, 2, 256],1)\n",
    "point_embeddings = nn.Embedding(1, 256), nn.Embedding(1, 256), nn.Embedding(1, 256), nn.Embedding(1, 256)\n",
    "\n",
    "corner_embedding[:, 0, :] += point_embeddings[2].weight\n",
    "corner_embedding[:, 1, :] += point_embeddings[3].weight\n",
    "print(corner_embedding.shape) # torch.Size([32, 2, 256])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7fd56de1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corner_embedding2 = random_tensor([32, 2, 256],1)\n",
    "\n",
    "corner_embedding2[:, 0, :] = corner_embedding2[:, 0, :]+ point_embeddings[2].weight\n",
    "corner_embedding2[:, 1, :] =corner_embedding2[:, 1, :]+ point_embeddings[3].weight\n",
    "print(corner_embedding.shape) # torch.Size([32, 2, 256])\n",
    "torch.equal(corner_embedding,corner_embedding2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9f9cda13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "        [[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "        [[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "        [[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]],\n",
       "\n",
       "        [[True, True, True,  ..., True, True, True],\n",
       "         [True, True, True,  ..., True, True, True]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corner_embedding3 = random_tensor([32, 2, 256],1)\n",
    "\n",
    "# Select and update specific slices along dimension 1\n",
    "corner_embedding_0 = torch.narrow(corner_embedding3, 1, 0, 1)\n",
    "corner_embedding_1 = torch.narrow(corner_embedding3, 1, 1, 1)\n",
    "\n",
    "# Use regular addition and assign the result to new tensors\n",
    "updated_corner_embedding_0 = corner_embedding_0 + point_embeddings[2].weight.squeeze(0).expand_as(corner_embedding_0)\n",
    "updated_corner_embedding_1 = corner_embedding_1 + point_embeddings[3].weight.squeeze(0).expand_as(corner_embedding_1)\n",
    "\n",
    "# Combine the updated slices back into the original tensor\n",
    "corner_embedding3 = torch.cat((updated_corner_embedding_0, updated_corner_embedding_1), dim=1)\n",
    "\n",
    "print(corner_embedding3.shape) # torch.Size([32, 2, 256]\n",
    "\n",
    "torch.eq(corner_embedding,corner_embedding3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
