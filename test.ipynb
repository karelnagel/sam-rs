{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7ad3bf14",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04ec4816",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "from helpers import Item, output_to_file,random_ndarray,random_tensor,build_sam_test,input_to_file\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "248a1f24",
   "metadata": {},
   "source": [
    "# Loading image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5df2ebd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1200, 1800, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "image = cv2.imread('images/truck.jpg')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "print(image.shape)\n",
    "items =[Item(\"image\",image,\"TensorInt\")]\n",
    "output_to_file(\"image\",items)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c0efaef2",
   "metadata": {},
   "source": [
    "## Common\n",
    "#### LayerNorm2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f813cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.modeling.common import LayerNorm2d\n",
    "\n",
    "layer_norm = LayerNorm2d(256,0.1)\n",
    "\n",
    "# Forward\n",
    "input = random_tensor([2,256,16,16],1)\n",
    "output = layer_norm(input)\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"layer_norm_2d\",items)\n",
    "del layer_norm, input, output,items"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6a99864",
   "metadata": {},
   "source": [
    "#### MLPBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6867373",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.modeling.common import MLPBlock\n",
    "mlp_block = MLPBlock(256,256,nn.GELU)\n",
    "input_to_file(\"mlp_block\",mlp_block)\n",
    "\n",
    "# Forward\n",
    "input = random_tensor([256,256],5)\n",
    "output = mlp_block(input)\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"mlp_block\",items)\n",
    "del mlp_block, input, output,items"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74fade84",
   "metadata": {},
   "source": [
    "# Image encoder"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56f80aac",
   "metadata": {},
   "source": [
    "#### PatchEmbeded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08dd2d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.modeling.image_encoder import PatchEmbed\n",
    "\n",
    "patch_embed = PatchEmbed((16,16),(16,16),(0,0),3,320)\n",
    "input_to_file(\"patch_embed\",patch_embed)\n",
    "\n",
    "# Forward\n",
    "input = random_tensor([1,3,512,512],3)\n",
    "output = patch_embed(input)\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"patch_embed\",items)\n",
    "del patch_embed, input, output,items"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f0abc93",
   "metadata": {},
   "source": [
    "#### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8241be48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.modeling.image_encoder import get_rel_pos,add_decomposed_rel_pos\n",
    "\n",
    "# Get rel pos\n",
    "q_size = 32\n",
    "k_size = 32\n",
    "input = random_tensor([127,40],1)\n",
    "output = get_rel_pos( q_size, k_size, input)\n",
    "items = [Item(\"input\",input,\"TensorFloat\"),Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"get_rel_pos\",items)\n",
    "del input, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6dcad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add decomposed rel pos\n",
    "attn = random_tensor([200,49,49],2)\n",
    "q = random_tensor([200,49,20],3)\n",
    "relo_pos_h = random_tensor([20,20],4)\n",
    "relo_pos_w = random_tensor([20,20],5)\n",
    "q_size = (7,7)\n",
    "k_size = (7,7)\n",
    "output = add_decomposed_rel_pos(attn,q,relo_pos_h,relo_pos_w,q_size,k_size)\n",
    "items = [Item(\"attn\", attn, \"TensorFloat\"), Item(\"q\", q, \"TensorFloat\"), Item(\"q_size\", q_size, \"Size\"), Item(\"k_size\", k_size, \"Size\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"add_decomposed_rel_pos\",items)\n",
    "del attn,q,relo_pos_h,relo_pos_w,q_size,k_size,output,items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825bf833",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.modeling.image_encoder import Attention\n",
    "\n",
    "# Attention\n",
    "attention = Attention(320, 16 ,True ,True ,True, (14, 14))\n",
    "input_to_file(\"attention\",attention)\n",
    "\n",
    "# Forward\n",
    "input = random_tensor([25,14,14,320],1)\n",
    "output = attention(input)\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"attention\",items)\n",
    "del input\n",
    "del output\n",
    "del attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d09b671",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.modeling.image_encoder import  window_partition,window_unpartition\n",
    "\n",
    "# Window partition\n",
    "input = random_tensor([2,256,16,16],1)\n",
    "output,size = window_partition(input,16)\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\"), Item(\"size\", size, \"Size\")]\n",
    "output_to_file(\"window_partition\",items)\n",
    "\n",
    "# Window unpartition\n",
    "input = random_tensor([2,256,16,16],2)\n",
    "output = window_unpartition(input,16,(16,16),(14,14))\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"window_unpartition\",items)\n",
    "del input, output, items"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38040f69",
   "metadata": {},
   "source": [
    "#### Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba0e9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.modeling.image_encoder import Block\n",
    "\n",
    "#Block\n",
    "block = Block(80,8,4.0,True,nn.LayerNorm,nn.GELU,True,True,14,(16,16))\n",
    "input_to_file(\"block\",block)\n",
    "#Forward\n",
    "input = random_tensor([1,16,16,80],1)\n",
    "output = block(input)\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"block\",items)\n",
    "del block, input, output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d4e1c390",
   "metadata": {},
   "source": [
    "#### Image encoderViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83369d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.modeling.image_encoder import ImageEncoderViT\n",
    "\n",
    "image_encoder = ImageEncoderViT(4,4,3,80,4,16,4.0,32,True,nn.LayerNorm,nn.GELU,True,True,True,14,[7,15,23,31])\n",
    "input_to_file(\"image_encoder\",image_encoder)\n",
    "\n",
    "input = random_tensor([1,3,4,4],1)\n",
    "output = image_encoder(input)\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"image_encoder\",items)\n",
    "\n",
    "del image_encoder\n",
    "del input\n",
    "del output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66c6f570",
   "metadata": {},
   "source": [
    "## Transformer\n",
    "#### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee398610",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.modeling.transformer import Attention\n",
    "\n",
    "attention = Attention(32,8,1)\n",
    "input_to_file(\"transformer_attention\",attention)\n",
    "\n",
    "#Forward\n",
    "q = random_tensor([1,32,32],1)\n",
    "k = random_tensor([1,32,32],2)\n",
    "v = random_tensor([1,32,32],3)\n",
    "output = attention.forward(q,k,v)\n",
    "items = [Item(\"q\", q, \"TensorFloat\"), Item(\"k\", k, \"TensorFloat\"), Item(\"v\", v, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"transformer_attention\",items)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c1c5c01",
   "metadata": {},
   "source": [
    "#### TwoWayAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ea625b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.modeling.transformer import TwoWayAttentionBlock\n",
    "\n",
    "block = TwoWayAttentionBlock(256,8,2048,nn.ReLU,2,False)\n",
    "input_to_file(\"transformer_two_way_attention_block\",block)\n",
    "\n",
    "#Forward\n",
    "queries = random_tensor([1,256,256],1)\n",
    "keys = random_tensor([1,256,256],2)\n",
    "query_pe = random_tensor([1,256,256],3)\n",
    "key_pe = random_tensor([1,256,256],4)\n",
    "out_queries,out_keys = block(queries,keys,query_pe,key_pe)\n",
    "items = [Item(\"queries\", queries, \"TensorFloat\"), Item(\"keys\", keys, \"TensorFloat\"), Item(\"query_pe\", query_pe, \"TensorFloat\"), Item(\"key_pe\", key_pe, \"TensorFloat\"), Item(\"out_queries\", out_queries, \"TensorFloat\"), Item(\"out_keys\", out_keys, \"TensorFloat\")]\n",
    "output_to_file(\"transformer_two_way_attention_block\",items)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3168b933",
   "metadata": {},
   "source": [
    "#### TwoWayTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fa73fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.modeling.transformer import TwoWayTransformer\n",
    "\n",
    "transformer = TwoWayTransformer(2, 64, 4, 256, nn.ReLU, 2)\n",
    "input_to_file(\"transformer_two_way_transformer\",transformer)\n",
    "\n",
    "# Forward\n",
    "image_embedding = random_tensor([1,64,16,16],1)\n",
    "image_pe = random_tensor([1,64,16,16],2)\n",
    "point_embedding = random_tensor([16, 256, 64],3)\n",
    "queries,keys = transformer(image_embedding,image_pe,point_embedding)\n",
    "items = [Item(\"image_embedding\", image_embedding, \"TensorFloat\"), Item(\"image_pe\", image_pe, \"TensorFloat\"), Item(\"point_embedding\", point_embedding, \"TensorFloat\"), Item(\"queries\", queries, \"TensorFloat\"), Item(\"keys\", keys, \"TensorFloat\")]\n",
    "output_to_file(\"transformer_two_way_transformer\",items)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0d5a673",
   "metadata": {},
   "source": [
    "## Mask decoder\n",
    "#### MLP block\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a847818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.modeling.mask_decoder import MLP\n",
    "\n",
    "mlp = MLP(256,256,256,4,False)\n",
    "input_to_file(\"mlp\",mlp)\n",
    "\n",
    "# Forward\n",
    "input = random_tensor([1,256],1)\n",
    "output = mlp(input)\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"mlp\",items)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "088e4ce7",
   "metadata": {},
   "source": [
    "#### Mask decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75fa9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.modeling.mask_decoder import MaskDecoder\n",
    "\n",
    "transformer = TwoWayTransformer(2, 64, 2, 512, nn.ReLU, 2)\n",
    "mask_decoder = MaskDecoder(transformer_dim=64,transformer=transformer,num_multimask_outputs=3, activation=nn.GELU,iou_head_depth=3,iou_head_hidden_dim=64)\n",
    "input_to_file(\"mask_decoder\",mask_decoder)\n",
    "\n",
    "# Forward\n",
    "image_embedding = random_tensor([1,64,16,16],1)\n",
    "image_pe = random_tensor([1,64,16,16],2)\n",
    "sparse_prompt_embeddings = random_tensor([16, 2, 64],3)\n",
    "dense_prompt_embeddings = random_tensor([16, 64, 16, 16],4)\n",
    "masks, iou_pred = mask_decoder(image_embedding,image_pe,sparse_prompt_embeddings,dense_prompt_embeddings,True)\n",
    "items = [Item(\"image_embedding\", image_embedding, \"TensorFloat\"), Item(\"image_pe\", image_pe, \"TensorFloat\"), Item(\"sparse_prompt_embeddings\", sparse_prompt_embeddings, \"TensorFloat\"), Item(\"dense_prompt_embeddings\", dense_prompt_embeddings, \"TensorFloat\"), Item(\"masks\", masks, \"TensorFloat\"), Item(\"iou_pred\", iou_pred, \"TensorFloat\")]\n",
    "output_to_file(\"mask_decoder\",items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a404f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict masks\n",
    "transformer = TwoWayTransformer(2, 64, 2, 512, nn.ReLU, 2)\n",
    "mask_decoder = MaskDecoder(transformer_dim=64,transformer=transformer,num_multimask_outputs=3, activation=nn.GELU,iou_head_depth=3,iou_head_hidden_dim=64)\n",
    "input_to_file(\"mask_decoder_predict\",mask_decoder)\n",
    "\n",
    "# Predict masks\n",
    "image_embedding = random_tensor([1,64,16,16],1)\n",
    "image_pe = random_tensor([1,64,16,16],2)\n",
    "sparse_prompt_embeddings = random_tensor([16, 2, 64],3)\n",
    "dense_prompt_embeddings = random_tensor([16, 64, 16, 16],4)\n",
    "masks, iou_pred = mask_decoder.predict_masks(image_embedding,image_pe,sparse_prompt_embeddings,dense_prompt_embeddings)\n",
    "items = [Item(\"image_embedding\", image_embedding, \"TensorFloat\"), Item(\"image_pe\", image_pe, \"TensorFloat\"), Item(\"sparse_prompt_embeddings\", sparse_prompt_embeddings, \"TensorFloat\"), Item(\"dense_prompt_embeddings\", dense_prompt_embeddings, \"TensorFloat\"), Item(\"masks\", masks, \"TensorFloat\"), Item(\"iou_pred\", iou_pred, \"TensorFloat\")]\n",
    "output_to_file(\"mask_decoder_predict\",items)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28bc7051",
   "metadata": {},
   "source": [
    "## Prompt Encoder\n",
    "#### Positional Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8b6651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.modeling.prompt_encoder import PositionEmbeddingRandom\n",
    "\n",
    "# _pe_encoding \n",
    "position_embedding = PositionEmbeddingRandom(128, None)\n",
    "input_to_file(\"position_embedding_random_pe_encoding\",position_embedding)\n",
    "\n",
    "input = random_tensor([64,69,2],1)\n",
    "output = position_embedding._pe_encoding(input)\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"position_embedding_random_pe_encoding\",items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e34461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward\n",
    "position_embedding = PositionEmbeddingRandom(128, None)\n",
    "input_to_file(\"position_embedding_random_forward\",position_embedding)\n",
    "\n",
    "input= (64,64)\n",
    "output = position_embedding.forward(input)\n",
    "items = [Item(\"input\", input, \"Size\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"position_embedding_random_forward\",items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d43ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward with coords\n",
    "position_embedding = PositionEmbeddingRandom(128, None)\n",
    "input_to_file(\"position_embedding_random_forward_with_coords\",position_embedding)\n",
    "\n",
    "input = random_tensor([64,2,2],1)\n",
    "image_size  = (1024,1024)\n",
    "output = position_embedding.forward_with_coords(input,image_size)\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"image_size\", image_size, \"Size\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"position_embedding_random_forward_with_coords\",items)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "74e8b344",
   "metadata": {},
   "source": [
    "#### Prompt Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6762b819",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.modeling.prompt_encoder import PromptEncoder\n",
    "\n",
    "mask_in_chans =8\n",
    "embed_dim =128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f0781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed points pad\n",
    "prompt_encoder = PromptEncoder(embed_dim,(32,32),(512,512),mask_in_chans,nn.GELU)\n",
    "input_to_file(\"prompt_encoder_embed_points_pad\",prompt_encoder)\n",
    "\n",
    "points = random_tensor([32,1,2],1)\n",
    "labels = random_tensor([32,1],2)\n",
    "output = prompt_encoder._embed_points(points,labels,True)\n",
    "items = [Item(\"points\", points, \"TensorFloat\"), Item(\"labels\", labels, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"prompt_encoder_embed_points_pad\",items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e09665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed points no pad\n",
    "prompt_encoder = PromptEncoder(embed_dim,(32,32),(512,512),mask_in_chans,nn.GELU)\n",
    "input_to_file(\"prompt_encoder_embed_points_no_pad\",prompt_encoder)\n",
    "\n",
    "points = random_tensor([32,1,2],1)\n",
    "labels = random_tensor([32,1],2)\n",
    "output = prompt_encoder._embed_points(points,labels,False)\n",
    "items = [Item(\"points\", points, \"TensorFloat\"), Item(\"labels\", labels, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"prompt_encoder_embed_points_no_pad\",items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed70436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed boxes\n",
    "prompt_encoder = PromptEncoder(embed_dim,(32,32),(512,512),mask_in_chans,nn.GELU)\n",
    "input_to_file(\"prompt_encoder_embed_boxes\",prompt_encoder)\n",
    "\n",
    "boxes = random_tensor([32,4],1)\n",
    "output = prompt_encoder._embed_boxes(boxes)\n",
    "items = [Item(\"boxes\", boxes, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"prompt_encoder_embed_boxes\",items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aabc62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Embed masks\n",
    "\n",
    "prompt_encoder = PromptEncoder(embed_dim,(32,32),(512,512),mask_in_chans,nn.GELU)\n",
    "input_to_file(\"prompt_encoder_embed_masks\",prompt_encoder)\n",
    "\n",
    "masks = random_tensor([8,1,4,4],1)\n",
    "output = prompt_encoder._embed_masks(masks)\n",
    "items = [Item(\"masks\", masks, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"prompt_encoder_embed_masks\",items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709e7f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward points\n",
    "prompt_encoder = PromptEncoder(embed_dim,(32,32),(512,512),mask_in_chans,nn.GELU)\n",
    "input_to_file(\"prompt_encoder_forward_points\",prompt_encoder)\n",
    "\n",
    "points = random_tensor([8,1,2],1),random_tensor([8,1],2)\n",
    "boxes = None\n",
    "masks = None\n",
    "sparse,dense = prompt_encoder.forward(points,boxes,masks)\n",
    "items = [Item(\"points\", points[0], \"TensorFloat\"),Item(\"labels\", points[1], \"TensorFloat\"), Item(\"sparse\", sparse, \"TensorFloat\"), Item(\"dense\", dense, \"TensorFloat\")]\n",
    "output_to_file(\"prompt_encoder_forward_points\",items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e35e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward boxes\n",
    "prompt_encoder = PromptEncoder(embed_dim,(32,32),(512,512),mask_in_chans,nn.GELU)\n",
    "input_to_file(\"prompt_encoder_forward_boxes\",prompt_encoder)\n",
    "\n",
    "points = None\n",
    "boxes = random_tensor([8,4],1)\n",
    "masks = None\n",
    "sparse,dense = prompt_encoder.forward(points,boxes,masks)\n",
    "items = [Item(\"boxes\", boxes, \"TensorFloat\"), Item(\"sparse\", sparse, \"TensorFloat\"), Item(\"dense\", dense, \"TensorFloat\")]\n",
    "output_to_file(\"prompt_encoder_forward_boxes\",items)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "827cddf0",
   "metadata": {},
   "source": [
    "## Utils\n",
    "#### ResizeLongestSide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4527860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.utils.transforms import ResizeLongestSide\n",
    "\n",
    "# Get Preprocess shape\n",
    "resize = ResizeLongestSide(64)\n",
    "output = resize.get_preprocess_shape(32,32,64)\n",
    "items = [Item(\"output\", output, \"Size\")]\n",
    "output_to_file(\"resize_get_preprocess_shape\",items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e257da28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply image\n",
    "resize = ResizeLongestSide(64)\n",
    "input = random_tensor([120,180,3],1).mul(255).type(torch.uint8).numpy()\n",
    "output = resize.apply_image(input)\n",
    "items = [Item(\"input\", input, \"TensorInt\"), Item(\"output\", output, \"TensorInt\")]\n",
    "output_to_file(\"resize_apply_image\",items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcde9cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply coords\n",
    "resize = ResizeLongestSide(64)\n",
    "\n",
    "input = random_tensor([1, 2,2],1).mul(255).type(torch.int).numpy()\n",
    "original_size = (1200,1800)\n",
    "output = resize.apply_coords(input,original_size)\n",
    "items = [Item(\"input\", torch.from_numpy(input).type(torch.int), \"TensorInt\"), Item(\"output\", torch.from_numpy(output).type(torch.float32), \"TensorFloat\")]\n",
    "output_to_file(\"resize_apply_coords\",items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6025f76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply boxes\n",
    "resize = ResizeLongestSide(64)\n",
    "\n",
    "boxes=random_tensor([1, 4],1).mul(255).type(torch.int).numpy()\n",
    "original_size = (1200,1800)\n",
    "output = resize.apply_boxes(boxes,original_size)\n",
    "items = [Item(\"boxes\", boxes, \"TensorInt\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"resize_apply_boxes\",items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e57a115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply image torch\n",
    "resize  = ResizeLongestSide(64)\n",
    "input = random_tensor([1, 3, 32, 32],1)\n",
    "output = resize.apply_image_torch(input)\n",
    "items = [Item(\"input\", input, \"TensorFloat\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"resize_apply_image_torch\",items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1daa58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply coords torch\n",
    "resize  = ResizeLongestSide(64)\n",
    "coords = random_tensor([32,32],1).mul(255).type(torch.int)\n",
    "original_size = (32,32)\n",
    "output = resize.apply_coords_torch(coords,original_size)\n",
    "items = [Item(\"coords\", coords, \"TensorInt\"), Item(\"original_size\", original_size, \"Size\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"resize_apply_coords_torch\",items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "566ae000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply boxes torch\n",
    "resize  = ResizeLongestSide(64)\n",
    "boxes = random_tensor([32,32],1).mul(255).type(torch.int)\n",
    "original_size = (32,32)\n",
    "output = resize.apply_boxes_torch(boxes,original_size)\n",
    "items = [Item(\"boxes\", boxes, \"TensorInt\"), Item(\"original_size\", original_size, \"Size\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"resize_apply_boxes_torch\",items)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8940f864",
   "metadata": {},
   "source": [
    "## Build Sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20eafa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything.build_sam import build_sam_vit_h,Sam,build_sam_vit_b,build_sam_vit_l\n",
    "\n",
    "def get_items(sam:Sam):\n",
    "    items = [\n",
    "        Item(\"mask_threshold\", sam.mask_threshold, \"Float\"),\n",
    "        Item(\"image_format\",sam.image_format, \"String\"),\n",
    "        Item(\"pixel_mean\", sam.pixel_mean, \"TensorFloat\"),\n",
    "        Item(\"pixel_std\", sam.pixel_std, \"TensorFloat\"),\n",
    "        Item(\"mask_decoder.num_mask_tokens\", sam.mask_decoder.num_mask_tokens, \"Int\"),\n",
    "        Item(\"prompt_encoder.embed_dim\", sam.prompt_encoder.embed_dim, \"Int\"),\n",
    "        Item(\"prompt_encoder.input_image_size\", sam.prompt_encoder.input_image_size, \"Size\"),\n",
    "    ]\n",
    "    return items\n",
    "\n",
    "sam_vit_h = build_sam_vit_h()\n",
    "output_to_file(\"sam_vit_h\",get_items(sam_vit_h))\n",
    "\n",
    "sam_vit_b = build_sam_vit_b()\n",
    "output_to_file(\"sam_vit_b\",get_items(sam_vit_b))\n",
    "\n",
    "sam_vit_l = build_sam_vit_l()\n",
    "output_to_file(\"sam_vit_l\",get_items(sam_vit_l))\n",
    "\n",
    "del sam_vit_h, sam_vit_b, sam_vit_l"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55130b9b",
   "metadata": {},
   "source": [
    "## Sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbc2869",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"sam-convert/sam_test.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e963fb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward boxes\n",
    "sam = build_sam_test(checkpoint)\n",
    "# input_to_file(\"sam_forward_boxes\",sam)\n",
    "batched_input = [\n",
    "     {\n",
    "         'image': random_tensor([3,8,8],1).mul(255).type(torch.int),\n",
    "         'boxes': random_tensor([4,4],1),\n",
    "         'original_size': (100,200)\n",
    "     },\n",
    "     {\n",
    "         'image': random_tensor([3,8,8],1).mul(255).type(torch.int),\n",
    "         'boxes': random_tensor([4,4],1),\n",
    "         'original_size': (50,80)\n",
    "     }\n",
    "]\n",
    "output = sam.forward(batched_input,False)\n",
    "items=[]\n",
    "for i,x in enumerate(output):\n",
    "    masks = x['masks']\n",
    "    items.append(Item(\"masks\"+str(i), masks, \"TensorBool\"))\n",
    "\n",
    "    iou_predictions = x['iou_predictions']\n",
    "    items.append(Item(\"iou_predictions\"+str(i), iou_predictions, \"TensorFloat\"))\n",
    "\n",
    "    if 'low_res_logits' in x:\n",
    "        low_res_masks = x['low_res_logits']\n",
    "        items.append(Item(\"low_res_logits\"+str(i), low_res_masks, \"TensorFloat\"))\n",
    "\n",
    "    \n",
    "output_to_file(\"sam_forward_boxes\",items)\n",
    "del sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e97f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward Points\n",
    "sam = build_sam_test(checkpoint)\n",
    "# input_to_file(\"sam_forward_points\",sam)\n",
    "batched_input = [\n",
    "     {\n",
    "         'image': random_tensor([3,8,8],1).mul(255).type(torch.int),\n",
    "         'original_size': (100,200),\n",
    "         'point_coords': random_tensor([4,2,2],1),\n",
    "         'point_labels': random_tensor([4,2],1)\n",
    "     },\n",
    "     {\n",
    "         'image': random_tensor([3,8,8],2).mul(255).type(torch.int),\n",
    "         'original_size': (50,80),\n",
    "         'point_coords': random_tensor([4,2,2],2),\n",
    "         'point_labels': random_tensor([4,2],2)\n",
    "         \n",
    "     }\n",
    "]\n",
    "output = sam.forward(batched_input,False)\n",
    "items=[]\n",
    "for i,x in enumerate(output):\n",
    "    masks = x['masks']\n",
    "    items.append(Item(\"masks\"+str(i), masks, \"TensorBool\"))\n",
    "\n",
    "    iou_predictions = x['iou_predictions']\n",
    "    items.append(Item(\"iou_predictions\"+str(i), iou_predictions, \"TensorFloat\"))\n",
    "\n",
    "    if 'low_res_logits' in x:\n",
    "        low_res_masks = x['low_res_logits']\n",
    "        items.append(Item(\"low_res_logits\"+str(i), low_res_masks, \"TensorFloat\"))\n",
    "\n",
    "    \n",
    "output_to_file(\"sam_forward_points\",items)\n",
    "del sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f6e903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postprocess masks\n",
    "sam = build_sam_test(checkpoint)\n",
    "\n",
    "masks = random_tensor([4,1,256,256],1)\n",
    "input_size = (684,1024)\n",
    "original_size = (534,800)\n",
    "output = sam.postprocess_masks(masks,input_size,original_size)\n",
    "items = [Item(\"masks\", masks, \"TensorFloat\"), Item(\"input_size\", input_size, \"Size\"), Item(\"original_size\", original_size, \"Size\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"sam_postprocess_masks\",items)\n",
    "del sam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9ae7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess\n",
    "sam = build_sam_test(checkpoint)\n",
    "\n",
    "input = random_tensor([3,171,128],1).mul(255).type(torch.int)\n",
    "output = sam.preprocess(input)\n",
    "items = [Item(\"input\", input, \"TensorInt\"), Item(\"output\", output, \"TensorFloat\")]\n",
    "output_to_file(\"sam_preprocess\",items)\n",
    "del sam"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16394c79",
   "metadata": {},
   "source": [
    "## Sam Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28df5df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init\n",
    "from segment_anything.predictor import SamPredictor\n",
    "\n",
    "def get_predictor(with_set_image:bool=False):\n",
    "    sam = build_sam_test(checkpoint)\n",
    "    predictor = SamPredictor(sam)\n",
    "    if with_set_image:\n",
    "        image = random_tensor([120,180,3],1).mul(255).type(torch.uint8).numpy()\n",
    "        predictor.set_image(image,\"RGB\")\n",
    "    return predictor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c109a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set image \n",
    "predictor = get_predictor(True)\n",
    "\n",
    "items=[\n",
    "    Item(\"original_size\",predictor.original_size,\"Size\"),\n",
    "    Item(\"input_size\",predictor.input_size,\"Size\"),\n",
    "    Item(\"features\",predictor.features,\"TensorFloat\"),\n",
    "    Item(\"is_image_set\",predictor.is_image_set,\"Bool\"),\n",
    "]\n",
    "output_to_file(\"predictor_set_image\",items)\n",
    "del predictor,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a85b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set torch image\n",
    "predictor = get_predictor()\n",
    "\n",
    "image = random_tensor([1, 3, 683, 1024],1).mul(255).type(torch.uint8)\n",
    "original_size = (120, 180)\n",
    "predictor.set_torch_image(image,original_size)\n",
    "items=[\n",
    "    Item(\"original_size\",predictor.original_size,\"Size\"),\n",
    "    Item(\"input_size\",predictor.input_size,\"Size\"),\n",
    "    Item(\"features\",predictor.features,\"TensorFloat\"),\n",
    "    Item(\"is_image_set\",predictor.is_image_set,\"Bool\"),\n",
    "]\n",
    "output_to_file(\"predictor_set_torch_image\",items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4667f824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "predictor = get_predictor(True)\n",
    "\n",
    "point_coords = random_ndarray([1,2],1)\n",
    "point_labels = random_tensor([1],1).type(torch.int).numpy()\n",
    "\n",
    "masks, iou_predictions, low_res_masks =predictor.predict(point_coords,point_labels,None,None,True,False)\n",
    "items =[\n",
    "    Item(\"masks\", masks, \"TensorBool\"),\n",
    "    Item(\"iou_predictions\", iou_predictions, \"TensorFloat\"),\n",
    "    Item(\"low_res_masks\", low_res_masks, \"TensorFloat\"),\n",
    "]\n",
    "output_to_file(\"predictor_predict\",items)\n",
    "del point_coords, point_labels, masks, iou_predictions, low_res_masks,predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62c1a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict torch\n",
    "predictor = get_predictor(True)\n",
    "\n",
    "point_coords = random_tensor([1,1,2],1)\n",
    "point_labels = random_tensor([1,1],1)\n",
    "masks, iou_predictions, low_res_masks = predictor.predict_torch(point_coords,point_labels,None,None,True,False)\n",
    "items =[\n",
    "    Item(\"masks\", masks, \"TensorBool\"),\n",
    "    Item(\"iou_predictions\",iou_predictions, \"TensorFloat\"),\n",
    "    Item(\"low_res_masks\", low_res_masks, \"TensorFloat\")\n",
    "]\n",
    "output_to_file(\"predictor_predict_torch\",items)\n",
    "del predictor,point_coords,point_labels,masks,iou_predictions,low_res_masks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
